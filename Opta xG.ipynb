{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "758cc48b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE WITH MATCHES FILE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vh/gd9x5_d94g33w411t0md800c0000gn/T/ipykernel_12011/951968058.py:118: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  matches['matchName'] = ''\n",
      "/var/folders/vh/gd9x5_d94g33w411t0md800c0000gn/T/ipykernel_12011/951968058.py:122: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  matches['matchName'][i] = f\"{matches['matchInfo/localDate'][i]}_{matches['matchInfo/contestant/0/officialName'][i]} - {matches['matchInfo/contestant/1/officialName'][i]}\"\n",
      "/var/folders/vh/gd9x5_d94g33w411t0md800c0000gn/T/ipykernel_12011/951968058.py:124: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  matches['matchInfo/localDate'] = pd.to_datetime(matches['matchInfo/localDate'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloaded - 2021-12-03_Wellington Phoenix FC - Western Sydney Wanderers FC\n",
      "downloaded - 2021-12-03_Canberra United - Melbourne City FC\n",
      "downloaded - 2021-12-04_Sydney FC - Newcastle Jets\n",
      "downloaded - 2021-12-04_Perth Glory FC - Brisbane Roar FC\n",
      "downloaded - 2021-12-05_Melbourne Victory - Adelaide United\n",
      "downloaded - 2021-12-10_Newcastle Jets - Wellington Phoenix FC\n",
      "downloaded - 2021-12-10_Brisbane Roar FC - Perth Glory FC\n",
      "downloaded - 2021-12-11_Western Sydney Wanderers FC - Sydney FC\n",
      "downloaded - 2021-12-12_Melbourne City FC - Melbourne Victory\n",
      "downloaded - 2021-12-12_Adelaide United - Canberra United\n",
      "downloaded - 2021-12-17_Western Sydney Wanderers FC - Newcastle Jets\n",
      "downloaded - 2021-12-18_Melbourne City FC - Adelaide United\n",
      "downloaded - 2021-12-18_Brisbane Roar FC - Melbourne Victory\n",
      "downloaded - 2021-12-19_Sydney FC - Wellington Phoenix FC\n",
      "downloaded - 2021-12-23_Canberra United - Brisbane Roar FC\n",
      "downloaded - 2021-12-26_Melbourne Victory - Melbourne City FC\n",
      "downloaded - 2021-12-27_Sydney FC - Western Sydney Wanderers FC\n",
      "downloaded - 2021-12-27_Wellington Phoenix FC - Newcastle Jets\n",
      "downloaded - 2021-12-30_Wellington Phoenix FC - Sydney FC\n",
      "downloaded - 2022-01-01_Adelaide United - Perth Glory FC\n",
      "downloaded - 2022-01-02_Melbourne Victory - Brisbane Roar FC\n",
      "downloaded - 2022-01-05_Perth Glory FC - Canberra United\n",
      "downloaded - 2022-01-08_Canberra United - Adelaide United\n",
      "downloaded - 2022-01-08_Sydney FC - Perth Glory FC\n",
      "downloaded - 2022-01-09_Melbourne City FC - Wellington Phoenix FC\n",
      "downloaded - 2022-01-09_Brisbane Roar FC - Western Sydney Wanderers FC\n",
      "downloaded - 2022-01-15_Sydney FC - Canberra United\n",
      "downloaded - 2022-01-15_Adelaide United - Melbourne City FC\n",
      "downloaded - 2022-01-16_Wellington Phoenix FC - Brisbane Roar FC\n",
      "downloaded - 2022-01-16_Western Sydney Wanderers FC - Melbourne Victory\n",
      "downloaded - 2022-01-16_Newcastle Jets - Perth Glory FC\n",
      "downloaded - 2022-01-21_Adelaide United - Wellington Phoenix FC\n",
      "downloaded - 2022-01-22_Sydney FC - Melbourne City FC\n",
      "downloaded - 2022-01-23_Perth Glory FC - Western Sydney Wanderers FC\n",
      "downloaded - 2022-01-28_Western Sydney Wanderers FC - Adelaide United\n",
      "downloaded - 2022-01-29_Brisbane Roar FC - Melbourne City FC\n",
      "downloaded - 2022-01-30_Newcastle Jets - Canberra United\n",
      "downloaded - 2022-01-31_Perth Glory FC - Wellington Phoenix FC\n",
      "downloaded - 2022-02-02_Sydney FC - Brisbane Roar FC\n",
      "downloaded - 2022-02-04_Adelaide United - Newcastle Jets\n",
      "downloaded - 2022-02-04_Wellington Phoenix FC - Melbourne Victory\n",
      "downloaded - 2022-02-05_Canberra United - Perth Glory FC\n",
      "downloaded - 2022-02-06_Melbourne City FC - Western Sydney Wanderers FC\n",
      "downloaded - 2022-02-08_Newcastle Jets - Melbourne Victory\n",
      "downloaded - 2022-02-10_Perth Glory FC - Adelaide United\n",
      "downloaded - 2022-02-11_Canberra United - Wellington Phoenix FC\n",
      "downloaded - 2022-02-12_Melbourne Victory - Western Sydney Wanderers FC\n",
      "downloaded - 2022-02-13_Perth Glory FC - Melbourne City FC\n",
      "downloaded - 2022-02-13_Brisbane Roar FC - Adelaide United\n",
      "downloaded - 2022-02-13_Newcastle Jets - Sydney FC\n",
      "downloaded - 2022-02-15_Western Sydney Wanderers FC - Canberra United\n",
      "downloaded - 2022-02-16_Melbourne Victory - Sydney FC\n",
      "downloaded - 2022-02-18_Wellington Phoenix FC - Adelaide United\n",
      "downloaded - 2022-02-19_Melbourne Victory - Perth Glory FC\n",
      "downloaded - 2022-02-19_Newcastle Jets - Western Sydney Wanderers FC\n",
      "downloaded - 2022-02-20_Melbourne City FC - Sydney FC\n",
      "downloaded - 2022-02-22_Canberra United - Melbourne Victory\n",
      "downloaded - 2022-02-24_Melbourne City FC - Brisbane Roar FC\n",
      "downloaded - 2022-02-25_Canberra United - Newcastle Jets\n",
      "downloaded - 2022-02-26_Adelaide United - Melbourne Victory\n",
      "downloaded - 2022-02-27_Perth Glory FC - Sydney FC\n",
      "downloaded - 2022-03-01_Western Sydney Wanderers FC - Wellington Phoenix FC\n",
      "downloaded - 2022-03-01_Melbourne City FC - Newcastle Jets\n",
      "downloaded - 2022-03-04_Melbourne Victory - Canberra United\n",
      "downloaded - 2022-03-04_Wellington Phoenix FC - Perth Glory FC\n",
      "downloaded - 2022-03-04_Newcastle Jets - Brisbane Roar FC\n",
      "downloaded - 2022-03-06_Western Sydney Wanderers FC - Melbourne City FC\n",
      "downloaded - 2022-03-06_Adelaide United - Sydney FC\n",
      "downloaded - 2022-03-07_Brisbane Roar FC - Newcastle Jets\n",
      "downloaded - 2022-03-10_Brisbane Roar FC - Canberra United\n",
      "downloaded - 2022-03-11_Sydney FC - Melbourne City FC\n",
      "downloaded - 2022-03-13_Adelaide United - Melbourne Victory\n",
      "downloaded - 2022-03-20_Melbourne City FC - Melbourne Victory\n",
      "downloaded - 2022-03-27_Sydney FC - Melbourne Victory\n",
      "DONE WITH EVERYTHING\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import clipboard\n",
    "import os\n",
    "import time\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import numpy as np\n",
    "\n",
    "########################################\n",
    "######### CHANGE THE INFO HERE #########\n",
    "########################################\n",
    "\n",
    "lg = 'A-League Women 2021-2022'\n",
    "lg_id = 'd6tuztyp7kqkmikytugafu3v8' # This is the league ID from Opta.. Can find it in the html of a league's page\n",
    "lg_schedule_location = \"/Users/user/xG\"\n",
    "#lg_schedule_location = \"/Users/marclamberts/Downloads\"/{lg}\" ## This is where you want the schedule of matches to download to\n",
    "#chromium_location = \"C:/Users/Ben/Coding/chromedriver.exe\"  ## This is the file path to where your Chromium program is\n",
    "match_download_location = \"/Users/user/xG/\"  ## This is the base folder that will house your league folders. Create a folder named the same as the lg variable in this filepath folder\n",
    "#from pathlib import Path\n",
    "#downloads_path = str(Path.home() / \"Downloads\")\n",
    "##################################################################################\n",
    "######### TO SAVE TIME, I MAKE SURE TO PUT A FILTERING MECHANISM #################\n",
    "######### IN THE CODE SO THAT IT ONLY GETS GAMES AFTER THE LAST RUN DATE #########\n",
    "######### ONCE YOU RUN A LEAGUE, ADD IT AND THE LAST RUN DATE ####################\n",
    "######### (two examples shown commented) #########################################\n",
    "##################################################################################\n",
    "from datetime import datetime, timedelta\n",
    "d = datetime.today() - timedelta(days=2)\n",
    "\n",
    "\n",
    "\n",
    "if lg == 'FBL':\n",
    "     last_run = \"2022-09-01\"\n",
    "if lg == 'Indian Super League':\n",
    "     last_run = \"2023-02-16\"\n",
    "else:\n",
    "    last_run = d.strftime('%Y-%m-%d')\n",
    "    last_run = '2019-07-19'\n",
    "\n",
    "##########################################################################\n",
    "\n",
    "url = \"https://api.performfeeds.com/soccerdata/match/qxcx5jmswgto1qeqcjzghtddt/?_rt=c&tmcl=%s&live=yes&_pgSz=400&_lcl=en&_fmt=jsonp&_clbk=W360b23205d13a5cdd46c315ae9c2097b829cbc909\" %lg_id\n",
    "\n",
    "page = requests.get(url, headers={'referer': 'scoresway.com'})\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "\n",
    "raw = soup.getText()\n",
    "start = raw.find('{\"match\"')+9\n",
    "output = raw[start:-2]\n",
    "\n",
    "#from pandas import json_normalize\n",
    "#dict = json.loads(output)\n",
    "#df2 = json_normalize(dict)\n",
    "#print(df2)\n",
    "#df2['matchInfo.localDate']\n",
    "options = webdriver.ChromeOptions()\n",
    "prefs = {\"download.default_directory\": lg_schedule_location}\n",
    "options.add_experimental_option(\"prefs\",prefs)\n",
    "\n",
    "driver = webdriver.Chrome(options=options)\n",
    "driver.get(\"https://konklone.io/json\")\n",
    "input_css = 'body > section.json > div.areas > textarea'\n",
    "\n",
    "# Connecting to it with our driver\n",
    "#input_area = driver.find_element_by_css_selector(input_css)\n",
    "input_area = driver.find_element(By.CSS_SELECTOR, input_css)#\n",
    "# Set the sentence into the clipboard\n",
    "clipboard.copy(output)\n",
    "# Making sure that there is no previous text\n",
    "input_area.clear()\n",
    "# Pasting the copied sentence into the input_area\n",
    "input_area.send_keys(Keys.SHIFT, Keys.INSERT)\n",
    "\n",
    "# CSS of the download button\n",
    "click_css = 'body > section.csv > p > span.rendered > a.download'\n",
    "\n",
    "# Click it\n",
    "#driver.find_element_by_css_selector(click_css).click()\n",
    "driver.find_element(By.CSS_SELECTOR, click_css).click()\n",
    "time.sleep(2)\n",
    "driver.close()\n",
    "\n",
    "path = f'{lg_schedule_location}'\n",
    "os.chdir(path)\n",
    "files = sorted(os.listdir(os.getcwd()), key=os.path.getmtime)\n",
    "os.rename(files[len(files)-1], '%s Matches.csv' %lg)\n",
    "print('DONE WITH MATCHES FILE')\n",
    "\n",
    "\n",
    "################################################################################################################\n",
    "################################################################################################################\n",
    "################################################################################################################\n",
    "################################################################################################################\n",
    "\n",
    "\n",
    "df = pd.read_csv('%s/%s Matches.csv' %(lg_schedule_location,lg))\n",
    "df.to_csv('%s/%s Matches.csv' %(lg_schedule_location,lg), encoding='utf-8-sig')\n",
    "\n",
    "\n",
    "df = pd.read_csv('%s/%s Matches.csv' %(lg_schedule_location,lg))\n",
    "\n",
    "df.dropna(subset=['liveData/matchDetails/scores/ft/home'],inplace=True)\n",
    "df.reset_index(drop=True,inplace=True)\n",
    "df = df[::-1].reset_index(drop=True)\n",
    "\n",
    "cols = ['matchInfo/localDate','matchInfo/id',\n",
    "        'matchInfo/contestant/0/officialName','liveData/matchDetails/scores/ft/home',\n",
    "        'liveData/matchDetails/scores/ft/away','matchInfo/contestant/1/officialName',\n",
    "        'matchInfo/contestant/0/id','matchInfo/contestant/1/id']\n",
    "matches = df[cols]\n",
    "\n",
    "matches['matchName'] = ''\n",
    "for i in range(len(matches)):\n",
    "    #matches['matchName'][i] = '%s %i-%i %s' %(matches['matchInfo/contestant/0/officialName'][i], matches['liveData/matchDetails/scores/ft/home'][i], matches['liveData/matchDetails/scores/ft/away'][i], matches['matchInfo/contestant/1/officialName'][i])\n",
    "    #matches['matchName'][i] = '%s - %s' % (matches['matchInfo/contestant/0/officialName'][i], matches['matchInfo/contestant/1/officialName'][i])\n",
    "    matches['matchName'][i] = f\"{matches['matchInfo/localDate'][i]}_{matches['matchInfo/contestant/0/officialName'][i]} - {matches['matchInfo/contestant/1/officialName'][i]}\"\n",
    "if last_run != '':\n",
    "    matches['matchInfo/localDate'] = pd.to_datetime(matches['matchInfo/localDate'])\n",
    "    matches = matches[matches['matchInfo/localDate']>pd.to_datetime(last_run)].reset_index(drop=True)\n",
    "idd = '57d4g9sd8u1salvv4eip2jhn8'\n",
    "for i in range(len(matches)):\n",
    "    url = \"https://api.performfeeds.com/soccerdata/matchevent/qxcx5jmswgto1qeqcjzghtddt/%s?_rt=c&_lcl=en&_fmt=jsonp&_clbk=W3bd804271ec7f49caa576ff8367109721760953b4\" %matches['matchInfo/id'][i]\n",
    "    #url = f\"https://api.performfeeds.com/soccerdata/matchevent/qxcx5jmswgto1qeqcjzghtddt/{idd}?_rt=c&_lcl=en&_fmt=jsonp&_clbk=W3bd804271ec7f49caa576ff8367109721760953b4\"\n",
    "\n",
    "    page = requests.get(url, headers={'referer': 'scoresway.com'})\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "\n",
    "    raw = soup.getText()\n",
    "    start = raw.find(\"liveData\")+10\n",
    "    output = raw[start:-2]\n",
    "\n",
    "    options = webdriver.ChromeOptions()\n",
    "    prefs = {\"download.default_directory\": \"%s/%s\" %(match_download_location,lg)}\n",
    "    options.add_experimental_option(\"prefs\",prefs)\n",
    "\n",
    "    # driver = webdriver.Chrome(chrome_options=options)\n",
    "    # driver.get(\"https://konklone.io/json\")\n",
    "    # input_css = 'body > section.json > div.areas > textarea'\n",
    "    #\n",
    "    # # Connecting to it with our driver\n",
    "    # #input_area = driver.find_element_by_css_selector(input_css)\n",
    "    # input_area = driver.find_element(By.CSS_SELECTOR, input_css)\n",
    "    # # Set the sentence into the clipboard\n",
    "    # clipboard.copy(output)\n",
    "    # # Making sure that there is no previous text\n",
    "    # input_area.clear()\n",
    "    # # Pasting the copied sentence into the input_area\n",
    "    # input_area.send_keys(Keys.SHIFT, Keys.INSERT)\n",
    "    #\n",
    "    # # CSS of the download button\n",
    "    # click_css = 'body > section.csv > p > span.rendered > a.download'\n",
    "    #\n",
    "    # # Click it\n",
    "    # #driver.find_element_by_css_selector(click_css).click()\n",
    "    # driver.find_element(By.CSS_SELECTOR, click_css).click()\n",
    "    # time.sleep(2)\n",
    "    # driver.close()\n",
    "    #\n",
    "    path = '%s/%s' %(match_download_location,lg)\n",
    "    os.chdir(path)\n",
    "    files = sorted(os.listdir(os.getcwd()), key=os.path.getmtime)\n",
    "    #os.rename(files[len(files)-1], '%s.csv' %matches.matchName[i])\n",
    "    import json\n",
    "\n",
    "    output1 = json.loads(output)\n",
    "\n",
    "    with open('data.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(output1, f, ensure_ascii=True, indent=4)\n",
    "    os.rename(\"data.json\", '%s.json' % matches.matchName[i].replace('/',''))\n",
    "    print('downloaded - %s' %matches.matchName[i])\n",
    "print('DONE WITH EVERYTHING')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e4472a",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
