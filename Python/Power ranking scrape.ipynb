{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cc1e0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1\n",
      "Scraping page 2\n",
      "Scraping page 3\n",
      "Scraping page 4\n",
      "Scraping page 5\n",
      "Scraping page 6\n",
      "Scraping page 7\n",
      "Scraping page 8\n",
      "Scraping page 9\n",
      "Scraping page 10\n",
      "Scraping page 11\n",
      "Scraping page 12\n",
      "Scraping page 13\n",
      "Scraping page 14\n",
      "Scraping page 15\n",
      "Scraping page 16\n",
      "Scraping page 17\n",
      "Scraping page 18\n",
      "Scraping page 19\n",
      "Scraping page 20\n",
      "Scraping page 21\n",
      "Scraping page 22\n",
      "Scraping page 23\n",
      "Scraping page 24\n",
      "Scraping page 25\n",
      "Scraping page 26\n",
      "Scraping page 27\n",
      "Scraping page 28\n",
      "Scraping page 29\n",
      "Scraping page 30\n",
      "Done scraping Opta club rankings.\n",
      "Data saved to opta_club_rankings_04122024.xlsx\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# Specify the path to your installed chromedriver executable\n",
    "CHROMEDRIVER_PATH = '/Users/marclambertes/Python/chromedriver'\n",
    "MAX_OPTA_PAGE_NUM = 30\n",
    "OPTA_URL = 'https://dataviz.theanalyst.com/opta-power-rankings/'\n",
    "\n",
    "def scrape_opta_club_rankings():\n",
    "    chrome_options = webdriver.ChromeOptions()    \n",
    "    options = [\n",
    "        '--headless',\n",
    "    ]\n",
    "\n",
    "    for option in options:\n",
    "        chrome_options.add_argument(option)\n",
    "\n",
    "    # Use the directly installed Chromedriver\n",
    "    chrome_options.add_argument(f\"webdriver.chrome.driver={CHROMEDRIVER_PATH}\")\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "    driver.get(OPTA_URL)\n",
    "    time.sleep(3)\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    table = soup.find('table')\n",
    "    headers = [th.text.strip() for th in table.find_all('th')]\n",
    "    headers = headers + ['id']\n",
    "\n",
    "    rows = []\n",
    "    page_num = 1\n",
    "\n",
    "    while page_num <= MAX_OPTA_PAGE_NUM:\n",
    "        print(f'Scraping page {page_num}')\n",
    "        \n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        table = soup.find('table')\n",
    "\n",
    "        for tr in table.find_all('tr'):\n",
    "            row = [td.text.strip() for td in tr.find_all('td')]\n",
    "            img = tr.select_one('img')\n",
    "            if img is None:\n",
    "                img_id = ''\n",
    "            else:\n",
    "                img_id = img['src'].split('&id=')[-1]\n",
    "            row.append(img_id)\n",
    "            if row:\n",
    "                rows.append(row)\n",
    "        \n",
    "        if page_num < MAX_OPTA_PAGE_NUM:\n",
    "            buttons = driver.find_elements(by=By.CSS_SELECTOR, value='button')\n",
    "            last_button = buttons[-1]\n",
    "            last_button.click()\n",
    "            \n",
    "        time.sleep(2)\n",
    "        page_num += 1\n",
    "\n",
    "    print('Done scraping Opta club rankings.')\n",
    "    driver.quit()\n",
    "    time.sleep(1)\n",
    "    \n",
    "    df = pd.DataFrame(rows, columns=headers)\n",
    "    df.dropna(subset=['team'], inplace=True)\n",
    "\n",
    "    # Save data to Excel file\n",
    "    excel_filename = 'opta_club_rankings_04122024.xlsx'\n",
    "    df.to_excel(excel_filename, index=False)\n",
    "    print(f'Data saved to {excel_filename}')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    scrape_opta_club_rankings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "199476e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     rank               team  rating  ranking change 7 days  \\\n",
      "0       1    Manchester City   100.0                      0   \n",
      "201   202  Raków Częstochowa    79.3                     20   \n",
      "200   201         Moreirense    79.3                    -23   \n",
      "199   200      Vasco da Gama    79.3                      4   \n",
      "198   199            Levante    79.3                      7   \n",
      "\n",
      "                            id  Tier  \n",
      "0    a3nyxabgsqlnqfkeg41m6tnpp     1  \n",
      "201  1sxaf8l7fknmucd72fdretogm     1  \n",
      "200  4a3yqn3kt1l18oklr7zxo4f1s     1  \n",
      "199  5ponlslulpugdlvd93n9yqu2b     1  \n",
      "198  4grc9qgcvusllap8h5j6gc5h5     1  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load the Excel file into a DataFrame\n",
    "df = pd.read_excel('opta_club_rankings_21092024.xlsx')\n",
    "\n",
    "# Step 2: Sort the DataFrame by Rating in descending order (highest ratings first)\n",
    "df_sorted = df.sort_values(by='rating', ascending=False)\n",
    "\n",
    "# Step 3: Create a new column 'Tier' with 10 tiers, where the highest ratings are in Tier 1\n",
    "df_sorted['Tier'] = pd.qcut(df_sorted['rating'], 10, labels=False)\n",
    "\n",
    "# Invert the tiers so that 0 becomes 10, 1 becomes 9, ..., and 9 becomes 1\n",
    "df_sorted['Tier'] = 10 - df_sorted['Tier']\n",
    "\n",
    "# Optional: Sort the DataFrame by the Tier column if needed\n",
    "df_sorted = df_sorted.sort_values(by='Tier')\n",
    "\n",
    "# Step 4: Save the updated DataFrame back to an Excel file (optional)\n",
    "df_sorted.to_excel('your_file_with_tiers.xlsx', index=False)\n",
    "\n",
    "# Display the first few rows to check\n",
    "print(df_sorted.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9feb664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the team name: Ipswich Town\n",
      "Input Team:\n",
      "Team: Ipswich Town\n",
      "Rating: 80.6\n",
      "Rank: 152\n",
      "\n",
      "     | team           |   rating |   rank\n",
      "-----+----------------+----------+--------\n",
      " 144 | Leicester City |     80.7 |    145\n",
      " 145 | Cincinnati     |     80.7 |    146\n",
      " 146 | Lech Poznań    |     80.7 |    147\n",
      " 147 | Nordsjælland   |     80.6 |    148\n",
      " 148 | Fluminense     |     80.6 |    149\n",
      " 149 | Leeds United   |     80.6 |    150\n",
      " 150 | Houston Dynamo |     80.6 |    151\n",
      " 152 | Racing Club    |     80.5 |    153\n",
      " 153 | Molde          |     80.5 |    154\n",
      " 154 | Brøndby        |     80.5 |    155\n",
      " 155 | Ludogorets     |     80.5 |    156\n",
      " 156 | Orlando City   |     80.5 |    157\n",
      " 157 | Monterrey      |     80.5 |    158\n",
      " 158 | Malmö FF       |     80.4 |    159\n",
      " 159 | Boca Juniors   |     80.4 |    160\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "df = pd.read_excel('opta_club_rankings_21092024.xlsx')\n",
    "\n",
    "\n",
    "# Assuming you have a DataFrame named df containing the team data\n",
    "\n",
    "# Enter the team name\n",
    "team_name = input(\"Enter the team name: \")\n",
    "\n",
    "# Filter the DataFrame to get the data for the specified team\n",
    "team_data = df[df['team'] == team_name]\n",
    "\n",
    "# Get the rating and ranking of the input team\n",
    "input_team_rating = team_data['rating'].values[0]\n",
    "input_team_ranking = team_data['rank'].values[0]\n",
    "\n",
    "# Print the rating and ranking for the input team\n",
    "print(\"Input Team:\")\n",
    "print(f\"Team: {team_name}\")\n",
    "print(f\"Rating: {input_team_rating}\")\n",
    "print(f\"Rank: {input_team_ranking}\")\n",
    "print()\n",
    "\n",
    "# Calculate the absolute difference between the input team's rating and the ratings of all other teams\n",
    "df['rating_difference'] = abs(df['rating'] - input_team_rating)\n",
    "\n",
    "# Sort the DataFrame by the rating difference in ascending order\n",
    "sorted_teams = df.sort_values('rating_difference')\n",
    "\n",
    "# Get the 15 teams closest to the input team based on ranking\n",
    "closest_teams = sorted_teams.iloc[1:16]\n",
    "\n",
    "# Sort the closest_teams DataFrame based on the \"ranking\" column\n",
    "closest_teams_sorted = closest_teams.sort_values('rank')\n",
    "\n",
    "# Create a new DataFrame with the closest teams, including their rating and ranking\n",
    "team_data = closest_teams_sorted[['team', 'rating', 'rank']]\n",
    "\n",
    "# Convert the DataFrame to a table format\n",
    "table = tabulate(team_data, headers='keys', tablefmt='presto')\n",
    "\n",
    "# Print the table\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5445803a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the first team name: Wycombe Wanderers\n",
      "Enter the second team name: Mladá Boleslav\n",
      "Team 1:\n",
      "Team: Wycombe Wanderers\n",
      "Rating: 69.3\n",
      "Ranking: 970\n",
      "\n",
      "Team 2:\n",
      "Team: Mladá Boleslav\n",
      "Rating: 73.3\n",
      "Ranking: 533\n",
      "\n",
      "Ranking Relationship: Wycombe Wanderers is ranked lower than Mladá Boleslav\n",
      "Difference in Ranking: 437 place(s)\n"
     ]
    }
   ],
   "source": [
    "## Enter the first team name\n",
    "team1_name = input(\"Enter the first team name: \")\n",
    "\n",
    "# Filter the DataFrame to get the data for the first team\n",
    "team1_data = df[df['team'] == team1_name]\n",
    "\n",
    "# Get the rating and ranking of the first team\n",
    "team1_rating = team1_data['rating'].values[0]\n",
    "team1_ranking = team1_data['rank'].values[0]\n",
    "\n",
    "# Enter the second team name\n",
    "team2_name = input(\"Enter the second team name: \")\n",
    "\n",
    "# Filter the DataFrame to get the data for the second team\n",
    "team2_data = df[df['team'] == team2_name]\n",
    "\n",
    "# Get the rating and ranking of the second team\n",
    "team2_rating = team2_data['rating'].values[0]\n",
    "team2_ranking = team2_data['rank'].values[0]\n",
    "\n",
    "# Calculate the difference in ranking between the two teams\n",
    "ranking_difference = abs(team1_ranking - team2_ranking)\n",
    "\n",
    "# Print the information for both teams\n",
    "print(\"Team 1:\")\n",
    "print(f\"Team: {team1_name}\")\n",
    "print(f\"Rating: {team1_rating}\")\n",
    "print(f\"Ranking: {team1_ranking}\")\n",
    "print()\n",
    "\n",
    "print(\"Team 2:\")\n",
    "print(f\"Team: {team2_name}\")\n",
    "print(f\"Rating: {team2_rating}\")\n",
    "print(f\"Ranking: {team2_ranking}\")\n",
    "print()\n",
    "\n",
    "# Determine the relationship between the two teams based on ranking\n",
    "if team1_ranking < team2_ranking:\n",
    "    relationship = f\"{team1_name} is ranked higher than {team2_name}\"\n",
    "elif team1_ranking > team2_ranking:\n",
    "    relationship = f\"{team1_name} is ranked lower than {team2_name}\"\n",
    "else:\n",
    "    relationship = f\"{team1_name} and {team2_name} are ranked equally\"\n",
    "\n",
    "# Print the relationship between the teams\n",
    "print(f\"Ranking Relationship: {relationship}\")\n",
    "print(f\"Difference in Ranking: {ranking_difference} place(s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c279718",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# Specify the path to your installed chromedriver executable\n",
    "CHROMEDRIVER_PATH = '/Users/marclambertes/Python/chromedriver'\n",
    "MAX_OPTA_PAGE_NUM = 30\n",
    "OPTA_URL = 'https://dataviz.theanalyst.com/opta-power-rankings/'\n",
    "\n",
    "def scrape_opta_club_rankings():\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    \n",
    "    # Remove '--headless' to allow viewing the browser for debugging\n",
    "    # chrome_options.add_argument(\"--headless\")  # Uncomment if you want headless mode again\n",
    "    \n",
    "    # Initialize the Chrome driver\n",
    "    chrome_options.add_argument(f\"webdriver.chrome.driver={CHROMEDRIVER_PATH}\")\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "    # Load the URL\n",
    "    driver.get(OPTA_URL)\n",
    "\n",
    "    try:\n",
    "        # Use JavaScript to click the WOMENS tab if normal click doesn't work\n",
    "        womens_tab = WebDriverWait(driver, 15).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, \"//button[contains(text(), 'WOMENS')]\"))\n",
    "        )\n",
    "        \n",
    "        # Scroll to the WOMENS tab to ensure it's visible and ready to be clicked\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView(true);\", womens_tab)\n",
    "        time.sleep(1)  # Wait for scrolling to finish\n",
    "\n",
    "        # Use JavaScript to click the button\n",
    "        driver.execute_script(\"arguments[0].click();\", womens_tab)\n",
    "        print('Successfully switched to WOMENS rankings.')\n",
    "        \n",
    "        # Wait for the table to load after switching to WOMENS\n",
    "        time.sleep(3)  # Adjust this delay as necessary depending on load time\n",
    "\n",
    "        # Wait for the table to be fully loaded and visible\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.TAG_NAME, 'table'))\n",
    "        )\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while trying to switch to WOMENS: {e}\")\n",
    "        driver.quit()\n",
    "        return\n",
    "\n",
    "    # Parse the page content after clicking the WOMENS tab\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    table = soup.find('table')\n",
    "    \n",
    "    # Ensure the table exists and extract headers\n",
    "    if not table:\n",
    "        print(\"Could not find the table on the page.\")\n",
    "        driver.quit()\n",
    "        return\n",
    "    \n",
    "    # Extract headers from the table\n",
    "    headers = [th.text.strip() for th in table.find_all('th')]\n",
    "    headers.append('id')  # Add an id column for image id or other unique data if needed\n",
    "\n",
    "    rows = []\n",
    "    page_num = 1\n",
    "\n",
    "    while page_num <= MAX_OPTA_PAGE_NUM:\n",
    "        print(f'Scraping page {page_num}')\n",
    "        \n",
    "        # Re-parse the page content on each iteration in case it changes\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        table = soup.find('table')\n",
    "\n",
    "        # Extract rows of data from the table\n",
    "        for tr in table.find_all('tr'):\n",
    "            row = [td.text.strip() for td in tr.find_all('td')]\n",
    "            img = tr.select_one('img')\n",
    "            img_id = img['src'].split('&id=')[-1] if img else ''  # Extract image ID if exists\n",
    "            row.append(img_id)\n",
    "            if row:\n",
    "                rows.append(row)\n",
    "        \n",
    "        # Check if there's another page to click through\n",
    "        if page_num < MAX_OPTA_PAGE_NUM:\n",
    "            try:\n",
    "                next_button = WebDriverWait(driver, 10).until(\n",
    "                    EC.element_to_be_clickable((By.XPATH, \"//button[contains(@class, 'next-button-class')]\"))\n",
    "                )\n",
    "                next_button.click()  # Click the next page button\n",
    "                time.sleep(2)  # Wait for the next page to load\n",
    "            except:\n",
    "                print(f\"No more pages after page {page_num}\")\n",
    "                break\n",
    "            \n",
    "        page_num += 1\n",
    "\n",
    "    print('Done scraping WOMENS club rankings.')\n",
    "    driver.quit()\n",
    "    time.sleep(1)\n",
    "    \n",
    "    # Save the data to a pandas DataFrame\n",
    "    df = pd.DataFrame(rows, columns=headers)\n",
    "    df.dropna(subset=['team'], inplace=True)\n",
    "\n",
    "    # Save the DataFrame to an Excel file\n",
    "    excel_filename = 'opta_club_rankings_womens_03102024.xlsx'\n",
    "    df.to_excel(excel_filename, index=False)\n",
    "    print(f'Data saved to {excel_filename}')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    scrape_opta_club_rankings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a0f742",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
