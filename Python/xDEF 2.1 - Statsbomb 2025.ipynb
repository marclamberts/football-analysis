{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7469e083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player totals saved to 'Player_Defensive_Impact_with_Team_and_xOBV.xlsx'\n",
      "\n",
      "üîù Top Overperforming Defenders (Prevent More Threat Than Expected):\n",
      "                 defender      team_name  normalized_obv_impact  \\\n",
      "6   El Hadji Malick Diouf   Slavia Praha               0.062372   \n",
      "19           Michal Koh√∫t  Ban√≠k Ostrava               0.887899   \n",
      "7             Erik Prekop  Ban√≠k Ostrava               0.588962   \n",
      "2            David Buchta  Ban√≠k Ostrava               0.290026   \n",
      "24             Tom√°≈° Rigo  Ban√≠k Ostrava               0.588962   \n",
      "15           Luk√°≈° Provod   Slavia Praha               0.098014   \n",
      "13             Ji≈ô√≠ Boula  Ban√≠k Ostrava               0.738431   \n",
      "14          Karel Pojezn√Ω  Ban√≠k Ostrava               0.514228   \n",
      "9            Filip Kubala  Ban√≠k Ostrava               0.327393   \n",
      "11              Igoh Ogbu   Slavia Praha               0.187117   \n",
      "\n",
      "    normalized_xOBV  overperformance  \n",
      "6          0.062130         0.000243  \n",
      "19         0.887690         0.000209  \n",
      "7          0.588890         0.000072  \n",
      "2          0.289972         0.000054  \n",
      "24         0.588911         0.000051  \n",
      "15         0.097975         0.000039  \n",
      "13         0.738393         0.000038  \n",
      "14         0.514195         0.000034  \n",
      "9          0.327368         0.000025  \n",
      "11         0.187094         0.000023  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Step 1: Load Data\n",
    "file_path = \"/Users/marclambertes/Downloads/Wyscout/Slavia Praha_Bohemians 1905_3941550.csv\"\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(file_path)\n",
    "    df.columns = df.columns.str.strip()  # Remove spaces in column names\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found at {file_path}\")\n",
    "    exit()\n",
    "\n",
    "# Step 2: Ensure Required Columns Exist\n",
    "required_cols = {'player_name', 'team_name', 'team_id', 'location_x', 'location_y', 'end_location_x', 'end_location_y',\n",
    "                 'event_type_name', 'under_pressure', 'pass_recipient_name', 'pass_success_probability',\n",
    "                 'obv_for_before', 'obv_for_after', 'obv_for_net'}\n",
    "\n",
    "missing_cols = required_cols - set(df.columns)\n",
    "if missing_cols:\n",
    "    print(\"Error: Missing columns:\", missing_cols)\n",
    "    exit()\n",
    "\n",
    "# Step 3: Filter Passes and Defensive Actions\n",
    "passes = df[df['event_type_name'] == 'Pass'].copy()\n",
    "defensive_actions = df[df['event_type_name'].isin(['Pressure', 'Tackle', 'Interception'])].copy()\n",
    "\n",
    "# Fill missing recipient names\n",
    "passes['pass_recipient_name'] = passes['pass_recipient_name'].fillna('Unknown')\n",
    "\n",
    "# Step 4: Match Defensive Actions to Passes\n",
    "matched_actions = []\n",
    "for _, pass_row in passes.iterrows():\n",
    "    for _, def_row in defensive_actions.iterrows():\n",
    "        if pass_row['team_id'] != def_row['team_id']:  # Opponent check\n",
    "            # Distance between pass location and defensive action\n",
    "            distance = np.sqrt((pass_row['end_location_x'] - def_row['location_x']) ** 2 +\n",
    "                               (pass_row['end_location_y'] - def_row['location_y']) ** 2)\n",
    "\n",
    "            # Determine pressing success based on under_pressure & pass outcome\n",
    "            pressing_successful = (pass_row['under_pressure'] and pass_row['obv_for_after'] < pass_row['obv_for_before'])\n",
    "\n",
    "            # Store matched data\n",
    "            matched_actions.append({\n",
    "                'defender': def_row['player_name'],\n",
    "                'team_name': def_row['team_name'],  # Include team name\n",
    "                'pressing_successful': 1 if pressing_successful else 0,\n",
    "                'pass_success_probability': pass_row['pass_success_probability'],\n",
    "                'obv_for_before': pass_row['obv_for_before'],\n",
    "                'obv_for_after': pass_row['obv_for_after'],\n",
    "                'obv_for_net': pass_row['obv_for_net'],\n",
    "                'distance': distance\n",
    "            })\n",
    "\n",
    "# Step 5: Convert to DataFrame\n",
    "matched_df = pd.DataFrame(matched_actions)\n",
    "\n",
    "# Step 6: Handle Missing Values\n",
    "matched_df.fillna(0, inplace=True)  # Replace all NaN with 0\n",
    "\n",
    "# Step 7: Train xOBV Model\n",
    "features = ['pressing_successful', 'pass_success_probability', 'distance']\n",
    "X = matched_df[features]\n",
    "y = matched_df['obv_for_net']  # The actual impact of defensive actions\n",
    "\n",
    "# Split data for training\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Random Forest Regressor\n",
    "xobv_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "xobv_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict xOBV for each defensive event\n",
    "matched_df['xOBV'] = xobv_model.predict(X)\n",
    "\n",
    "# Step 8: Calculate Totals for Each Defender (Now Including Team Name)\n",
    "player_totals = matched_df.groupby(['defender', 'team_name']).agg(\n",
    "    total_pressures=('pressing_successful', 'count'),  # Total defensive actions\n",
    "    successful_pressures=('pressing_successful', 'sum'),  # Successful pressures\n",
    "    total_obv_impact=('obv_for_net', 'sum'),  # Sum of actual OBV impact\n",
    "    expected_obv_impact=('xOBV', 'sum'),  # Expected OBV impact (xOBV)\n",
    "    avg_distance=('distance', 'mean')  # Average distance to the pass event\n",
    ").reset_index()\n",
    "\n",
    "# Calculate pressing success rate\n",
    "player_totals['pressing_success_rate'] = player_totals['successful_pressures'] / player_totals['total_pressures']\n",
    "player_totals.fillna(0, inplace=True)  # Ensure no NaNs due to division\n",
    "\n",
    "# Normalize OBV Impact (Scale between 0 and 1)\n",
    "scaler = MinMaxScaler()\n",
    "player_totals[['normalized_obv_impact', 'normalized_xOBV']] = scaler.fit_transform(\n",
    "    player_totals[['total_obv_impact', 'expected_obv_impact']]\n",
    ")\n",
    "\n",
    "# Calculate Overperformance (Actual vs Expected)\n",
    "player_totals['overperformance'] = player_totals['normalized_obv_impact'] - player_totals['normalized_xOBV']\n",
    "\n",
    "# Step 9: Save Player Stats (WITH TEAM NAME)\n",
    "output_filename = \"Player_Defensive_Impact_with_Team_and_xOBV.xlsx\"\n",
    "player_totals.to_excel(output_filename, index=False)\n",
    "print(f\"Player totals saved to '{output_filename}'\")\n",
    "\n",
    "# Step 10: Print Top Defenders by Overperformance\n",
    "print(\"\\nüîù Top Overperforming Defenders (Prevent More Threat Than Expected):\")\n",
    "print(player_totals[['defender', 'team_name', 'normalized_obv_impact', 'normalized_xOBV', 'overperformance']].sort_values(\n",
    "    by='overperformance', ascending=False).head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "93098df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Player totals saved to 'Slavia Praha_BaniÃÅk Ostrava_Defensive_Impact.xlsx'\n",
      "\n",
      "üîù Top Defenders Overall (Highest aDEF_Total):\n",
      "           defender      team_name  aDEF_Interception  aDEF_Pressure  \\\n",
      "16     Matƒõj Chalu≈°  Ban√≠k Ostrava           0.077221       1.000000   \n",
      "19     Michal Koh√∫t  Ban√≠k Ostrava           0.077221       0.874167   \n",
      "13       Ji≈ô√≠ Boula  Ban√≠k Ostrava                NaN       0.832222   \n",
      "18  Michal Frydrych  Ban√≠k Ostrava                NaN       0.706389   \n",
      "24       Tom√°≈° Rigo  Ban√≠k Ostrava                NaN       0.664444   \n",
      "7       Erik Prekop  Ban√≠k Ostrava                NaN       0.664444   \n",
      "14    Karel Pojezn√Ω  Ban√≠k Ostrava                NaN       0.580555   \n",
      "9      Filip Kubala  Ban√≠k Ostrava                NaN       0.370833   \n",
      "2      David Buchta  Ban√≠k Ostrava                NaN       0.328888   \n",
      "17        Matƒõj ≈†√≠n  Ban√≠k Ostrava                NaN       0.328888   \n",
      "\n",
      "    xDEF_Interception  xDEF_Pressure  aDEF_Total  xDEF_Total  \n",
      "16           0.096131       1.000000    1.077221    1.096131  \n",
      "19           0.100757       0.878200    0.951388    0.978957  \n",
      "13                NaN       0.831323    0.832222    0.831323  \n",
      "18                NaN       0.705346    0.706389    0.705346  \n",
      "24                NaN       0.668254    0.664444    0.668254  \n",
      "7                 NaN       0.666809    0.664444    0.666809  \n",
      "14                NaN       0.579973    0.580555    0.579973  \n",
      "9                 NaN       0.372282    0.370833    0.372282  \n",
      "2                 NaN       0.327120    0.328888    0.327120  \n",
      "17                NaN       0.327266    0.328888    0.327266  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Step 1: Load Data\n",
    "file_path = \"/Users/marclambertes/Downloads/Wyscout/Slavia Praha_BaniÃÅk Ostrava_3941530.csv\"\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(file_path)\n",
    "    df.columns = df.columns.str.strip()  # Remove spaces in column names\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found at {file_path}\")\n",
    "    exit()\n",
    "\n",
    "# Step 2: Ensure Required Columns Exist\n",
    "required_cols = {'player_name', 'team_name', 'team_id', 'location_x', 'location_y', 'end_location_x', 'end_location_y',\n",
    "                 'event_type_name', 'under_pressure', 'pass_recipient_name', 'pass_success_probability',\n",
    "                 'obv_for_before', 'obv_for_after', 'obv_for_net'}\n",
    "\n",
    "missing_cols = required_cols - set(df.columns)\n",
    "if missing_cols:\n",
    "    print(\"Error: Missing columns:\", missing_cols)\n",
    "    exit()\n",
    "\n",
    "# Step 3: Filter Passes and Defensive Actions\n",
    "passes = df[df['event_type_name'] == 'Pass'].copy()\n",
    "defensive_actions = df[df['event_type_name'].isin(['Pressure', 'Tackle', 'Interception'])].copy()\n",
    "\n",
    "# Fill missing recipient names\n",
    "passes['pass_recipient_name'] = passes['pass_recipient_name'].fillna('Unknown')\n",
    "\n",
    "# Step 4: Match Defensive Actions to Passes\n",
    "matched_actions = []\n",
    "for _, pass_row in passes.iterrows():\n",
    "    for _, def_row in defensive_actions.iterrows():\n",
    "        if pass_row['team_id'] != def_row['team_id']:  # Opponent check\n",
    "            # Distance between pass location and defensive action\n",
    "            distance = np.sqrt((pass_row['end_location_x'] - def_row['location_x']) ** 2 +\n",
    "                               (pass_row['end_location_y'] - def_row['location_y']) ** 2)\n",
    "\n",
    "            # Determine pressing success based on under_pressure & pass outcome\n",
    "            pressing_successful = (pass_row['under_pressure'] and pass_row['obv_for_after'] < pass_row['obv_for_before'])\n",
    "\n",
    "            # Assign weights based on event type (Pressure > Tackle > Interception)\n",
    "            event_weight = {\n",
    "                'Pressure': 1.2,  # Higher weight for pressing\n",
    "                'Tackle': 1.0,\n",
    "                'Interception': 0.8  # Lower weight for interceptions\n",
    "            }.get(def_row['event_type_name'], 1.0)\n",
    "\n",
    "            # Apply weight to OBV impact\n",
    "            weighted_obv = pass_row['obv_for_net'] * event_weight\n",
    "\n",
    "            # Store matched data\n",
    "            matched_actions.append({\n",
    "                'defender': def_row['player_name'],\n",
    "                'team_name': def_row['team_name'],  # Include team name\n",
    "                'event_type_name': def_row['event_type_name'],  # Defensive action type\n",
    "                'pressing_successful': 1 if pressing_successful else 0,\n",
    "                'pass_success_probability': pass_row['pass_success_probability'],\n",
    "                'obv_for_before': pass_row['obv_for_before'],\n",
    "                'obv_for_after': pass_row['obv_for_after'],\n",
    "                'weighted_obv': weighted_obv,  # Weighted OBV impact\n",
    "                'distance': distance\n",
    "            })\n",
    "\n",
    "# Step 5: Convert to DataFrame\n",
    "matched_df = pd.DataFrame(matched_actions)\n",
    "\n",
    "# Step 6: Handle Missing Values\n",
    "matched_df.fillna(0, inplace=True)  # Replace all NaN with 0\n",
    "\n",
    "# Step 7: Train xDEF Model (Learning from Weighted OBV)\n",
    "features = ['pressing_successful', 'pass_success_probability', 'distance']\n",
    "X = matched_df[features]\n",
    "y = matched_df['weighted_obv']  # Using weighted OBV for training\n",
    "\n",
    "# Split data for training\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Random Forest Regressor\n",
    "xdef_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "xdef_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict xDEF for each defensive event\n",
    "matched_df['xDEF'] = xdef_model.predict(X)\n",
    "\n",
    "# Step 8: Calculate Totals for Each Defender by Event Type\n",
    "player_totals = matched_df.groupby(['defender', 'team_name', 'event_type_name']).agg(\n",
    "    aDEF=('weighted_obv', 'sum'),  # Actual Defensive Impact\n",
    "    xDEF=('xDEF', 'sum')  # Expected Defensive Impact\n",
    ").reset_index()\n",
    "\n",
    "# Normalize aDEF & xDEF (Scale between 0 and 1)\n",
    "scaler = MinMaxScaler()\n",
    "player_totals[['aDEF', 'xDEF']] = scaler.fit_transform(player_totals[['aDEF', 'xDEF']])\n",
    "\n",
    "# Pivot to get separate columns for Pressure, Tackle, Interception\n",
    "player_totals_pivot = player_totals.pivot(index=['defender', 'team_name'], columns='event_type_name', values=['aDEF', 'xDEF'])\n",
    "\n",
    "# Flatten MultiIndex columns\n",
    "player_totals_pivot.columns = [f\"{col[0]}_{col[1]}\" for col in player_totals_pivot.columns]\n",
    "\n",
    "# Reset index to make it a proper DataFrame\n",
    "player_totals_pivot.reset_index(inplace=True)\n",
    "\n",
    "# Step 9: Compute Total aDEF and xDEF\n",
    "player_totals_pivot['aDEF_Total'] = player_totals_pivot.filter(like='aDEF_').sum(axis=1)\n",
    "player_totals_pivot['xDEF_Total'] = player_totals_pivot.filter(like='xDEF_').sum(axis=1)\n",
    "\n",
    "# Step 10: Generate Output Filename Based on Match Title\n",
    "filename = os.path.basename(file_path)  # Get only the file name\n",
    "match_title = \"_\".join(filename.split(\"_\")[:2])  # Extract up to second underscore\n",
    "\n",
    "# Construct output file name\n",
    "output_filename = f\"{match_title}_Defensive_Impact.xlsx\"\n",
    "\n",
    "# Save the file with NaN values replaced by 0\n",
    "player_totals_pivot.to_excel(output_filename, index=False, na_rep=0)\n",
    "\n",
    "print(f\"‚úÖ Player totals saved to '{output_filename}'\")\n",
    "\n",
    "# Step 11: Print Top Defenders by Total aDEF\n",
    "print(\"\\nüîù Top Defenders Overall (Highest aDEF_Total):\")\n",
    "print(player_totals_pivot.sort_values(by='aDEF_Total', ascending=False).head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d6ed17cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed Column Names: ['Player', 'Position', 'Team', 'third', 'channel', 'Minutes played per match', 'Adjusted min TIP per match', 'Count performances that pass the quality check', 'Count performances that fail the quality check', 'Count Runs in sample', 'Count Runs per Match', 'Count Dangerous Runs per Match', 'Threat of Runs per Match', 'Count Runs leading to goal per Match', 'Count Runs targeted per Match', 'Count Runs received per Match', 'Count Runs leading to shot per Match', 'Threat of Runs targeted per Match', 'Threat of Runs received per Match', 'Count dangerous Runs targeted per Match', 'Count dangerous Runs received per Match']\n",
      "Fixed CSV saved as 'final_fixed_file.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to your CSV file\n",
    "file_path = \"/Users/marclambertes/Downloads/Wyscout/SkillCorner-2025-02-23.csv\"\n",
    "\n",
    "# Read the CSV with the correct delimiter\n",
    "df = pd.read_csv(file_path, sep=\";\", encoding=\"utf-8\")\n",
    "\n",
    "# Print column names to check if they are correctly separated\n",
    "print(\"Fixed Column Names:\", df.columns.tolist())\n",
    "\n",
    "# Ensure \"Player\" column exists before proceeding\n",
    "if \"Player\" in df.columns:\n",
    "    # Function to fix unclosed quotation marks in the \"Player\" column\n",
    "    def fix_unclosed_quotes(player_name):\n",
    "        if isinstance(player_name, str) and player_name.startswith(\"'\") and not player_name.endswith(\"'\"):\n",
    "            return player_name + \"'\"  # Add the closing quote\n",
    "        return player_name  # Keep it unchanged\n",
    "\n",
    "    # Apply the function\n",
    "    df[\"Player\"] = df[\"Player\"].apply(fix_unclosed_quotes)\n",
    "\n",
    "    # Save the cleaned file\n",
    "    df.to_csv(\"final_fixed_file.csv\", index=False, sep=\";\")\n",
    "    print(\"Fixed CSV saved as 'final_fixed_file.csv'.\")\n",
    "else:\n",
    "    print(\"Error: 'Player' column not found after fixing headers!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7c2a717c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Player totals saved to 'Slavia Praha_BaniÃÅk Ostrava_Defensive_Impact.xlsx'\n",
      "\n",
      "üîù Top Defenders Overall (Highest aDEF_Total):\n",
      "            defender      team_name  aDEF_Interception  aDEF_Pressure  \\\n",
      "11      Matƒõj Chalu≈°  Ban√≠k Ostrava           0.078095       1.000000   \n",
      "13      Michal Koh√∫t  Ban√≠k Ostrava           0.078095       0.874286   \n",
      "8         Ji≈ô√≠ Boula  Ban√≠k Ostrava                NaN       0.832381   \n",
      "12   Michal Frydrych  Ban√≠k Ostrava                NaN       0.706666   \n",
      "5        Erik Prekop  Ban√≠k Ostrava                NaN       0.664762   \n",
      "9      Karel Pojezn√Ω  Ban√≠k Ostrava                NaN       0.580952   \n",
      "2       David Buchta  Ban√≠k Ostrava                NaN       0.329523   \n",
      "1      Daniel Holzer  Ban√≠k Ostrava                NaN       0.287619   \n",
      "6          Igoh Ogbu   Slavia Praha           0.011430       0.157159   \n",
      "15  ≈†tƒõp√°n Chaloupek   Slavia Praha           0.005715       0.140014   \n",
      "\n",
      "    xDEF_Interception  xDEF_Pressure  aDEF_Total  xDEF_Total  \n",
      "11           0.097275       1.000000    1.078095    1.097275  \n",
      "13           0.101084       0.878685    0.952380    0.979769  \n",
      "8                 NaN       0.834213    0.832381    0.834213  \n",
      "12                NaN       0.702010    0.706666    0.702010  \n",
      "5                 NaN       0.668608    0.664762    0.668608  \n",
      "9                 NaN       0.581626    0.580952    0.581626  \n",
      "2                 NaN       0.325392    0.329523    0.325392  \n",
      "1                 NaN       0.286707    0.287619    0.286707  \n",
      "6            0.015060       0.155139    0.168589    0.170198  \n",
      "15           0.006990       0.136822    0.145729    0.143812  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# --- Step 1: Load First CSV (SkillCorner) and Rename Column ---\n",
    "file_path1 = \"/Users/marclambertes/Downloads/Wyscout/SkillCorner-2025-02-23.csv\"\n",
    "\n",
    "# Read with correct delimiter\n",
    "df1 = pd.read_csv(file_path1, sep=\";\", encoding=\"utf-8\")\n",
    "df1.columns = df1.columns.str.replace('\"', '').str.strip()  # Remove stray quotes and spaces\n",
    "\n",
    "# Rename 'Player' to 'player_name' for merging\n",
    "if \"Player\" in df1.columns:\n",
    "    df1.rename(columns={\"Player\": \"player_name\"}, inplace=True)\n",
    "else:\n",
    "    print(\"Error: 'Player' column not found in first dataset!\")\n",
    "    exit()\n",
    "\n",
    "# --- Step 2: Load Second CSV (Match Data) ---\n",
    "file_path2 = \"/Users/marclambertes/Downloads/Wyscout/Slavia Praha_BaniÃÅk Ostrava_3941530.csv\"\n",
    "\n",
    "try:\n",
    "    df2 = pd.read_csv(file_path2)\n",
    "    df2.columns = df2.columns.str.strip()  # Remove spaces in column names\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found at {file_path2}\")\n",
    "    exit()\n",
    "\n",
    "# --- Step 3: Merge Datasets on 'player_name' ---\n",
    "df_merged = df1.merge(df2, on=\"player_name\", how=\"inner\")  # Use 'inner' to keep only matching rows\n",
    "\n",
    "# --- Step 4: Ensure Required Columns Exist ---\n",
    "required_cols = {'player_name', 'team_name', 'team_id', 'location_x', 'location_y', 'end_location_x', 'end_location_y',\n",
    "                 'event_type_name', 'under_pressure', 'pass_recipient_name', 'pass_success_probability',\n",
    "                 'obv_for_before', 'obv_for_after', 'obv_for_net'}\n",
    "\n",
    "missing_cols = required_cols - set(df_merged.columns)\n",
    "if missing_cols:\n",
    "    print(\"Error: Missing columns after merge:\", missing_cols)\n",
    "    exit()\n",
    "\n",
    "# --- Step 5: Filter Passes and Defensive Actions ---\n",
    "passes = df_merged[df_merged['event_type_name'] == 'Pass'].copy()\n",
    "defensive_actions = df_merged[df_merged['event_type_name'].isin(['Pressure', 'Tackle', 'Interception'])].copy()\n",
    "\n",
    "# Fill missing recipient names\n",
    "passes['pass_recipient_name'] = passes['pass_recipient_name'].fillna('Unknown')\n",
    "\n",
    "# --- Step 6: Match Defensive Actions to Passes ---\n",
    "matched_actions = []\n",
    "for _, pass_row in passes.iterrows():\n",
    "    for _, def_row in defensive_actions.iterrows():\n",
    "        if pass_row['team_id'] != def_row['team_id']:  # Opponent check\n",
    "            # Distance between pass location and defensive action\n",
    "            distance = np.sqrt((pass_row['end_location_x'] - def_row['location_x']) ** 2 +\n",
    "                               (pass_row['end_location_y'] - def_row['location_y']) ** 2)\n",
    "\n",
    "            # Determine pressing success based on under_pressure & pass outcome\n",
    "            pressing_successful = (pass_row['under_pressure'] and pass_row['obv_for_after'] < pass_row['obv_for_before'])\n",
    "\n",
    "            # Assign weights based on event type (Pressure > Tackle > Interception)\n",
    "            event_weight = {\n",
    "                'Pressure': 1.2,  # Higher weight for pressing\n",
    "                'Tackle': 1.0,\n",
    "                'Interception': 0.8  # Lower weight for interceptions\n",
    "            }.get(def_row['event_type_name'], 1.0)\n",
    "\n",
    "            # Apply weight to OBV impact\n",
    "            weighted_obv = pass_row['obv_for_net'] * event_weight\n",
    "\n",
    "            # Store matched data\n",
    "            matched_actions.append({\n",
    "                'defender': def_row['player_name'],\n",
    "                'team_name': def_row['team_name'],\n",
    "                'event_type_name': def_row['event_type_name'],\n",
    "                'pressing_successful': 1 if pressing_successful else 0,\n",
    "                'pass_success_probability': pass_row['pass_success_probability'],\n",
    "                'obv_for_before': pass_row['obv_for_before'],\n",
    "                'obv_for_after': pass_row['obv_for_after'],\n",
    "                'weighted_obv': weighted_obv,\n",
    "                'distance': distance\n",
    "            })\n",
    "\n",
    "# --- Step 7: Convert to DataFrame ---\n",
    "matched_df = pd.DataFrame(matched_actions)\n",
    "\n",
    "# --- Step 8: Handle Missing Values ---\n",
    "matched_df.fillna(0, inplace=True)\n",
    "\n",
    "# --- Step 9: Train xDEF Model ---\n",
    "features = ['pressing_successful', 'pass_success_probability', 'distance']\n",
    "X = matched_df[features]\n",
    "y = matched_df['weighted_obv']\n",
    "\n",
    "# Split data for training\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Random Forest Regressor\n",
    "xdef_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "xdef_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict xDEF for each defensive event\n",
    "matched_df['xDEF'] = xdef_model.predict(X)\n",
    "\n",
    "# --- Step 10: Calculate Totals for Each Defender by Event Type ---\n",
    "player_totals = matched_df.groupby(['defender', 'team_name', 'event_type_name']).agg(\n",
    "    aDEF=('weighted_obv', 'sum'),\n",
    "    xDEF=('xDEF', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# Normalize aDEF & xDEF\n",
    "scaler = MinMaxScaler()\n",
    "player_totals[['aDEF', 'xDEF']] = scaler.fit_transform(player_totals[['aDEF', 'xDEF']])\n",
    "\n",
    "# Pivot to separate columns for Pressure, Tackle, Interception\n",
    "player_totals_pivot = player_totals.pivot(index=['defender', 'team_name'], columns='event_type_name', values=['aDEF', 'xDEF'])\n",
    "\n",
    "# Flatten MultiIndex columns\n",
    "player_totals_pivot.columns = [f\"{col[0]}_{col[1]}\" for col in player_totals_pivot.columns]\n",
    "player_totals_pivot.reset_index(inplace=True)\n",
    "\n",
    "# --- Step 11: Compute Total aDEF and xDEF ---\n",
    "player_totals_pivot['aDEF_Total'] = player_totals_pivot.filter(like='aDEF_').sum(axis=1)\n",
    "player_totals_pivot['xDEF_Total'] = player_totals_pivot.filter(like='xDEF_').sum(axis=1)\n",
    "\n",
    "# --- Step 12: Generate Output Filename ---\n",
    "filename = os.path.basename(file_path2)\n",
    "match_title = \"_\".join(filename.split(\"_\")[:2])\n",
    "output_filename = f\"{match_title}_Defensive_Impact.xlsx\"\n",
    "\n",
    "# Save the file\n",
    "player_totals_pivot.to_excel(output_filename, index=False, na_rep=0)\n",
    "\n",
    "print(f\"‚úÖ Player totals saved to '{output_filename}'\")\n",
    "\n",
    "# --- Step 13: Print Top Defenders ---\n",
    "print(\"\\nüîù Top Defenders Overall (Highest aDEF_Total):\")\n",
    "print(player_totals_pivot.sort_values(by='aDEF_Total', ascending=False).head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d05d4660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Player totals saved to 'Slavia Praha_Bohemians 1905_Defensive_Impact.xlsx'\n",
      "\n",
      "üîù Top Defenders Overall (Highest aDEF_Total):\n",
      "                 defender       team_name  aDEF_Interception  aDEF_Pressure  \\\n",
      "20           Robert Hrub√Ω  Bohemians 1905                NaN       1.000000   \n",
      "26          V√°clav Drchal  Bohemians 1905                NaN       0.673850   \n",
      "9         Dominik Ple≈°til  Bohemians 1905                NaN       0.653633   \n",
      "15          Martin Dost√°l  Bohemians 1905           0.058589       0.527630   \n",
      "10  El Hadji Malick Diouf    Slavia Praha                NaN       0.461645   \n",
      "16          Mojm√≠r Chytil    Slavia Praha                NaN       0.454673   \n",
      "22            Tom√°≈° Hole≈°    Slavia Praha           0.078489       0.353231   \n",
      "21            Tom√°≈° Chor√Ω    Slavia Praha                NaN       0.402187   \n",
      "17           Ond≈ôej Lingr    Slavia Praha                NaN       0.308970   \n",
      "3          Anton√≠n K≈ôapka  Bohemians 1905                NaN       0.234893   \n",
      "\n",
      "    xDEF_Interception  xDEF_Pressure  aDEF_Total  xDEF_Total  \n",
      "20                NaN       1.000000    1.000000    1.000000  \n",
      "26                NaN       0.659737    0.673850    0.659737  \n",
      "9                 NaN       0.605097    0.653633    0.605097  \n",
      "15           0.055906       0.567658    0.586219    0.623564  \n",
      "10                NaN       0.455320    0.461645    0.455320  \n",
      "16                NaN       0.489293    0.454673    0.489293  \n",
      "22           0.070513       0.336582    0.431720    0.407094  \n",
      "21                NaN       0.383520    0.402187    0.383520  \n",
      "17                NaN       0.395810    0.308970    0.395810  \n",
      "3                 NaN       0.319653    0.234893    0.319653  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# --- Step 1: Load First CSV (SkillCorner) and Rename Column ---\n",
    "file_path1 = \"/Users/marclambertes/Downloads/Wyscout/SkillCorner-2025-03-09.csv\"\n",
    "\n",
    "# Read with correct delimiter\n",
    "df1 = pd.read_csv(file_path1, sep=\";\", encoding=\"utf-8\")\n",
    "df1.columns = df1.columns.str.replace('\"', '').str.strip()  # Remove stray quotes and spaces\n",
    "\n",
    "# Rename 'Player' to 'player_name' for merging\n",
    "if \"Player\" in df1.columns:\n",
    "    df1.rename(columns={\"Player\": \"player_name\"}, inplace=True)\n",
    "else:\n",
    "    print(\"Error: 'Player' column not found in first dataset!\")\n",
    "    exit()\n",
    "\n",
    "# Select relevant columns for runs\n",
    "run_cols = [\"player_name\", \"Count Runs targeted per Match\", \"Count Runs received per Match\"]\n",
    "df_runs = df1[run_cols]\n",
    "\n",
    "# --- Step 2: Load Second CSV (Match Data) ---\n",
    "file_path2 = \"/Users/marclambertes/Downloads/Wyscout/Slavia Praha_Bohemians 1905_3941550.csv\"\n",
    "\n",
    "try:\n",
    "    df2 = pd.read_csv(file_path2)\n",
    "    df2.columns = df2.columns.str.strip()  # Remove spaces in column names\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found at {file_path2}\")\n",
    "    exit()\n",
    "\n",
    "# --- Step 3: Merge Datasets on 'player_name' ---\n",
    "df_merged = df2.merge(df_runs, on=\"player_name\", how=\"left\")  # Include run statistics\n",
    "\n",
    "# Fill missing values in run columns with 0\n",
    "df_merged.fillna({\"Count Runs targeted per Match\": 0, \"Count Runs received per Match\": 0}, inplace=True)\n",
    "\n",
    "# --- Step 4: Ensure Required Columns Exist ---\n",
    "required_cols = {'player_name', 'team_name', 'team_id', 'location_x', 'location_y', 'end_location_x', 'end_location_y',\n",
    "                 'event_type_name', 'under_pressure', 'pass_recipient_name', 'pass_success_probability',\n",
    "                 'obv_for_before', 'obv_for_after', 'obv_for_net', 'Count Runs targeted per Match', 'Count Runs received per Match'}\n",
    "\n",
    "missing_cols = required_cols - set(df_merged.columns)\n",
    "if missing_cols:\n",
    "    print(\"Error: Missing columns after merge:\", missing_cols)\n",
    "    exit()\n",
    "\n",
    "# --- Step 5: Filter Passes and Defensive Actions ---\n",
    "passes = df_merged[df_merged['event_type_name'] == 'Pass'].copy()\n",
    "defensive_actions = df_merged[df_merged['event_type_name'].isin(['Pressure', 'Tackle', 'Interception'])].copy()\n",
    "\n",
    "# Fill missing recipient names\n",
    "passes['pass_recipient_name'] = passes['pass_recipient_name'].fillna('Unknown')\n",
    "\n",
    "# --- Step 6: Match Defensive Actions to Passes ---\n",
    "matched_actions = []\n",
    "for _, pass_row in passes.iterrows():\n",
    "    for _, def_row in defensive_actions.iterrows():\n",
    "        if pass_row['team_id'] != def_row['team_id']:  # Opponent check\n",
    "            # Distance between pass location and defensive action\n",
    "            distance = np.sqrt((pass_row['end_location_x'] - def_row['location_x']) ** 2 +\n",
    "                               (pass_row['end_location_y'] - def_row['location_y']) ** 2)\n",
    "\n",
    "            # Determine pressing success based on under_pressure & pass outcome\n",
    "            pressing_successful = (pass_row['under_pressure'] and pass_row['obv_for_after'] < pass_row['obv_for_before'])\n",
    "\n",
    "            # Assign weights based on event type (Pressure > Tackle > Interception)\n",
    "            event_weight = {\n",
    "                'Pressure': 1.2,\n",
    "                'Tackle': 1.0,\n",
    "                'Interception': 0.8\n",
    "            }.get(def_row['event_type_name'], 1.0)\n",
    "\n",
    "            # Apply weight to OBV impact and incorporate run statistics\n",
    "            weighted_obv = pass_row['obv_for_net'] * event_weight\n",
    "\n",
    "            # Adjust defensive value based on runs\n",
    "            run_targeted_weight = def_row['Count Runs targeted per Match'] * 0.5  # Weight for targeted runs\n",
    "            run_received_weight = def_row['Count Runs received per Match'] * 0.3  # Weight for received runs\n",
    "            adjusted_weighted_obv = weighted_obv + run_targeted_weight + run_received_weight\n",
    "\n",
    "            # Store matched data\n",
    "            matched_actions.append({\n",
    "                'defender': def_row['player_name'],\n",
    "                'team_name': def_row['team_name'],\n",
    "                'event_type_name': def_row['event_type_name'],\n",
    "                'pressing_successful': 1 if pressing_successful else 0,\n",
    "                'pass_success_probability': pass_row['pass_success_probability'],\n",
    "                'obv_for_before': pass_row['obv_for_before'],\n",
    "                'obv_for_after': pass_row['obv_for_after'],\n",
    "                'weighted_obv': adjusted_weighted_obv,\n",
    "                'distance': distance\n",
    "            })\n",
    "\n",
    "# --- Step 7: Convert to DataFrame ---\n",
    "matched_df = pd.DataFrame(matched_actions)\n",
    "\n",
    "# --- Step 8: Handle Missing Values ---\n",
    "matched_df.fillna(0, inplace=True)\n",
    "\n",
    "# --- Step 9: Train xDEF Model ---\n",
    "features = ['pressing_successful', 'pass_success_probability', 'distance']\n",
    "X = matched_df[features]\n",
    "y = matched_df['weighted_obv']\n",
    "\n",
    "# Split data for training\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Random Forest Regressor\n",
    "xdef_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "xdef_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict xDEF for each defensive event\n",
    "matched_df['xDEF'] = xdef_model.predict(X)\n",
    "\n",
    "# --- Step 10: Calculate Totals for Each Defender by Event Type ---\n",
    "player_totals = matched_df.groupby(['defender', 'team_name', 'event_type_name']).agg(\n",
    "    aDEF=('weighted_obv', 'sum'),\n",
    "    xDEF=('xDEF', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# Normalize aDEF & xDEF\n",
    "scaler = MinMaxScaler()\n",
    "player_totals[['aDEF', 'xDEF']] = scaler.fit_transform(player_totals[['aDEF', 'xDEF']])\n",
    "\n",
    "# Pivot to separate columns for Pressure, Tackle, Interception\n",
    "player_totals_pivot = player_totals.pivot(index=['defender', 'team_name'], columns='event_type_name', values=['aDEF', 'xDEF'])\n",
    "\n",
    "# Flatten MultiIndex columns\n",
    "player_totals_pivot.columns = [f\"{col[0]}_{col[1]}\" for col in player_totals_pivot.columns]\n",
    "player_totals_pivot.reset_index(inplace=True)\n",
    "\n",
    "# --- Step 11: Compute Total aDEF and xDEF ---\n",
    "player_totals_pivot['aDEF_Total'] = player_totals_pivot.filter(like='aDEF_').sum(axis=1)\n",
    "player_totals_pivot['xDEF_Total'] = player_totals_pivot.filter(like='xDEF_').sum(axis=1)\n",
    "\n",
    "# --- Step 12: Generate Output Filename ---\n",
    "filename = os.path.basename(file_path2)\n",
    "match_title = \"_\".join(filename.split(\"_\")[:2])\n",
    "output_filename = f\"{match_title}_Defensive_Impact.xlsx\"\n",
    "\n",
    "# Save the file\n",
    "player_totals_pivot.to_excel(output_filename, index=False, na_rep=0)\n",
    "\n",
    "print(f\"‚úÖ Player totals saved to '{output_filename}'\")\n",
    "\n",
    "# --- Step 13: Print Top Defenders ---\n",
    "print(\"\\nüîù Top Defenders Overall (Highest aDEF_Total):\")\n",
    "print(player_totals_pivot.sort_values(by='aDEF_Total', ascending=False).head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "580401fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-09 16:25:09,620 - INFO - ‚úÖ Processed data saved to '/Users/marclambertes/Downloads/Wyscout/Processed_Defensive_Actions.xlsx'\n"
     ]
    }
   ],
   "source": [
    "# --- Step 1: Load First CSV (SkillCorner) and Rename Column ---\n",
    "file_path1 = \"/Users/marclambertes/Downloads/Wyscout/SkillCorner-2025-03-09.csv\"\n",
    "\n",
    "try:\n",
    "    df1 = pd.read_csv(file_path1, sep=\";\", encoding=\"utf-8\")\n",
    "    df1.columns = df1.columns.str.replace('\"', '').str.strip()  # Remove stray quotes and spaces\n",
    "\n",
    "    # Rename 'Player' to 'player_name' for merging\n",
    "    if \"Player\" in df1.columns:\n",
    "        df1.rename(columns={\"Player\": \"player_name\"}, inplace=True)\n",
    "    else:\n",
    "        logging.error(\"Error: 'Player' column not found in first dataset!\")\n",
    "        exit()\n",
    "\n",
    "    # Select relevant columns for runs\n",
    "    run_cols = [\"player_name\", \"Count Runs targeted per Match\", \"Count Runs received per Match\"]\n",
    "    \n",
    "    # Check if the required columns exist in df1\n",
    "    missing_run_cols = set(run_cols) - set(df1.columns)\n",
    "    if missing_run_cols:\n",
    "        logging.error(f\"Error: Missing columns in first dataset: {missing_run_cols}\")\n",
    "        exit()\n",
    "\n",
    "    df_runs = df1[run_cols]\n",
    "\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error loading first CSV: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- Step 2: Load Second CSV (Match Data) ---\n",
    "file_path2 = \"/Users/marclambertes/Downloads/Wyscout/Slavia Praha_Bohemians 1905_3941550.csv\"\n",
    "\n",
    "try:\n",
    "    df2 = pd.read_csv(file_path2)\n",
    "    df2.columns = df2.columns.str.strip()  # Remove spaces in column names\n",
    "except FileNotFoundError:\n",
    "    logging.error(f\"Error: File not found at {file_path2}\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error loading second CSV: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- Step 3: Merge Datasets on 'player_name' ---\n",
    "df_merged = df2.merge(df_runs, on=\"player_name\", how=\"left\")  # Include run statistics\n",
    "\n",
    "# Check if the run columns were successfully merged\n",
    "if 'Count Runs targeted per Match' not in df_merged.columns or 'Count Runs received per Match' not in df_merged.columns:\n",
    "    logging.error(\"Error: Run columns not found after merge!\")\n",
    "    exit()\n",
    "\n",
    "# Fill missing values in run columns with 0\n",
    "df_merged.fillna({\"Count Runs targeted per Match\": 0, \"Count Runs received per Match\": 0}, inplace=True)\n",
    "\n",
    "# --- Step 4: Ensure Required Columns Exist ---\n",
    "required_cols = {'player_name', 'team_name', 'team_id', 'location_x', 'location_y', 'end_location_x', 'end_location_y',\n",
    "                 'event_type_name', 'under_pressure', 'pass_recipient_name', 'pass_success_probability',\n",
    "                 'obv_for_before', 'obv_for_after', 'obv_for_net', 'Count Runs targeted per Match', 'Count Runs received per Match'}\n",
    "\n",
    "missing_cols = required_cols - set(df_merged.columns)\n",
    "if missing_cols:\n",
    "    logging.error(f\"Error: Missing columns after merge: {missing_cols}\")\n",
    "    exit()\n",
    "\n",
    "# --- Step 5: Filter Passes and Defensive Actions ---\n",
    "passes = df_merged[df_merged['event_type_name'] == 'Pass'].copy()\n",
    "defensive_actions = df_merged[df_merged['event_type_name'].isin(['Pressure', 'Tackle', 'Interception'])].copy()\n",
    "\n",
    "# Fill missing recipient names\n",
    "passes['pass_recipient_name'] = passes['pass_recipient_name'].fillna('Unknown')\n",
    "\n",
    "# --- Step 6: Match Defensive Actions to Passes ---\n",
    "matched_actions = []\n",
    "for _, pass_row in passes.iterrows():\n",
    "    for _, def_row in defensive_actions.iterrows():\n",
    "        if pass_row['team_id'] != def_row['team_id']:  # Opponent check\n",
    "            # Distance between pass location and defensive action\n",
    "            distance = np.sqrt((pass_row['end_location_x'] - def_row['location_x']) ** 2 +\n",
    "                               (pass_row['end_location_y'] - def_row['location_y']) ** 2)\n",
    "\n",
    "            # Determine pressing success based on under_pressure & pass outcome\n",
    "            pressing_successful = (pass_row['under_pressure'] and pass_row['obv_for_after'] < pass_row['obv_for_before'])\n",
    "\n",
    "            # Assign weights based on event type (Pressure > Tackle > Interception)\n",
    "            event_weight = {\n",
    "                'Pressure': 1.2,\n",
    "                'Tackle': 1.0,\n",
    "                'Interception': 0.8\n",
    "            }.get(def_row['event_type_name'], 1.0)\n",
    "\n",
    "            # Apply weight to OBV impact and incorporate run statistics\n",
    "            weighted_obv = pass_row['obv_for_net'] * event_weight\n",
    "\n",
    "            # Adjust defensive value based on runs\n",
    "            run_targeted_weight = def_row['Count Runs targeted per Match'] * 0.5  # Weight for targeted runs\n",
    "            run_received_weight = def_row['Count Runs received per Match'] * 0.3  # Weight for received runs\n",
    "            adjusted_weighted_obv = weighted_obv + run_targeted_weight + run_received_weight\n",
    "\n",
    "            # Store matched data\n",
    "            matched_actions.append({\n",
    "                'defender': def_row['player_name'],\n",
    "                'team_name': def_row['team_name'],\n",
    "                'event_type_name': def_row['event_type_name'],\n",
    "                'pressing_successful': 1 if pressing_successful else 0,\n",
    "                'pass_success_probability': pass_row['pass_success_probability'],\n",
    "                'obv_for_before': pass_row['obv_for_before'],\n",
    "                'obv_for_after': pass_row['obv_for_after'],\n",
    "                'weighted_obv': adjusted_weighted_obv,\n",
    "                'distance': distance,\n",
    "                'Count Runs targeted per Match': def_row['Count Runs targeted per Match'],  # Ensure this is included\n",
    "                'Count Runs received per Match': def_row['Count Runs received per Match']   # Ensure this is included\n",
    "            })\n",
    "\n",
    "# --- Step 7: Convert to DataFrame ---\n",
    "matched_df = pd.DataFrame(matched_actions)\n",
    "\n",
    "# --- Step 8: Handle Missing Values ---\n",
    "matched_df.fillna(0, inplace=True)\n",
    "\n",
    "# --- Step 9: Feature Engineering ---\n",
    "# Ensure the columns exist before creating new features\n",
    "if 'Count Runs targeted per Match' in matched_df.columns and 'Count Runs received per Match' in matched_df.columns:\n",
    "    matched_df['defensive_action_strength'] = matched_df['event_type_name'].map({'Pressure': 1.2, 'Tackle': 1.0, 'Interception': 0.8})\n",
    "    matched_df['run_impact'] = matched_df['Count Runs targeted per Match'] * 0.5 + matched_df['Count Runs received per Match'] * 0.3\n",
    "else:\n",
    "    logging.error(\"Error: Run columns missing in matched_df!\")\n",
    "    exit()\n",
    "    \n",
    "# --- Step 10: Save to New Excel File ---\n",
    "output_file_path = \"/Users/marclambertes/Downloads/Wyscout/Processed_Defensive_Actions.xlsx\"\n",
    "\n",
    "try:\n",
    "    # Save the DataFrame to an Excel file\n",
    "    matched_df.to_excel(output_file_path, index=False, engine='openpyxl')\n",
    "    logging.info(f\"‚úÖ Processed data saved to '{output_file_path}'\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error saving to Excel: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a777cba4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
