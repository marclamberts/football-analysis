{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ef36e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully switched to WOMENS rankings.\n",
      "Scraping page 1\n",
      "Scraping page 2\n",
      "Scraping page 3\n",
      "Scraping page 4\n",
      "Scraping page 5\n",
      "Scraping page 6\n",
      "Scraping page 7\n",
      "Scraping page 8\n",
      "Scraping page 9\n",
      "Scraping page 10\n",
      "Scraping page 11\n",
      "Scraping page 12\n",
      "Scraping page 13\n",
      "Scraping page 14\n",
      "Scraping page 15\n",
      "Scraping page 16\n",
      "Scraping page 17\n",
      "Scraping page 18\n",
      "Scraping page 19\n",
      "Scraping page 20\n",
      "Scraping page 21\n",
      "Scraping page 22\n",
      "Scraping page 23\n",
      "Done scraping WOMENS club rankings.\n",
      "Data saved to opta_club_rankings_womens_23112024.xlsx\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# Specify the path to your installed chromedriver executable\n",
    "CHROMEDRIVER_PATH = '/Users/marclambertes/Python/chromedriver'\n",
    "OPTA_URL = 'https://dataviz.theanalyst.com/opta-power-rankings/'\n",
    "\n",
    "def scrape_opta_club_rankings():\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    \n",
    "    # Optional: Add headless mode if you don't need to view the browser\n",
    "    # chrome_options.add_argument(\"--headless\")\n",
    "    \n",
    "    # Initialize the Chrome driver\n",
    "    chrome_options.add_argument(f\"webdriver.chrome.driver={CHROMEDRIVER_PATH}\")\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "    # Load the URL\n",
    "    driver.get(OPTA_URL)\n",
    "\n",
    "    # Wait for the page to load\n",
    "    time.sleep(5)\n",
    "\n",
    "    try:\n",
    "        # Locate the \"WOMENS\" div using its text content and simulate a click\n",
    "        womens_tab = WebDriverWait(driver, 15).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, \"//div[text()='womens']\"))\n",
    "        )\n",
    "        \n",
    "        # Scroll to the WOMENS tab to make sure it's visible before clicking\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView(true);\", womens_tab)\n",
    "        time.sleep(1)  # Wait for scrolling to finish\n",
    "\n",
    "        # Click the WOMENS tab\n",
    "        womens_tab.click()\n",
    "        print('Successfully switched to WOMENS rankings.')\n",
    "        \n",
    "        # Allow time for the table to load after switching to WOMENS\n",
    "        time.sleep(3)  # Adjust this delay as necessary depending on load time\n",
    "\n",
    "        # Wait for the table to be fully loaded\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.TAG_NAME, 'table'))\n",
    "        )\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while trying to switch to WOMENS: {e}\")\n",
    "        driver.quit()\n",
    "        return\n",
    "\n",
    "    rows = []\n",
    "    page_num = 1\n",
    "    max_pages = 23  # Set the max number of pages to 23\n",
    "\n",
    "    # Scrape multiple pages (up to 23)\n",
    "    while page_num <= max_pages:\n",
    "        print(f'Scraping page {page_num}')\n",
    "        \n",
    "        # Parse the page content\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        table = soup.find('table')\n",
    "\n",
    "        # Ensure the table exists and extract headers only on the first page\n",
    "        if page_num == 1:\n",
    "            headers = [th.text.strip() for th in table.find_all('th')]\n",
    "            headers.append('id')  # Add an id column for image id or other unique data if needed\n",
    "\n",
    "        # Extract rows of data from the table\n",
    "        for tr in table.find_all('tr'):\n",
    "            row = [td.text.strip() for td in tr.find_all('td')]\n",
    "            img = tr.select_one('img')\n",
    "            img_id = img['src'].split('&id=')[-1] if img else ''  # Extract image ID if exists\n",
    "            row.append(img_id)\n",
    "            if row:\n",
    "                rows.append(row)\n",
    "        \n",
    "        # Try to locate the \">\" button and click it\n",
    "        if page_num < max_pages:  # Only try clicking \"Next\" if we're below the max page count\n",
    "            try:\n",
    "                next_button = WebDriverWait(driver, 10).until(\n",
    "                    EC.element_to_be_clickable((By.XPATH, \"//button[text()='>']\"))\n",
    "                )\n",
    "                next_button.click()  # Click the \">\" (Next) button\n",
    "                time.sleep(3)  # Wait for the next page to load\n",
    "            except:\n",
    "                print(f\"No more pages after page {page_num}\")\n",
    "                break\n",
    "        \n",
    "        page_num += 1\n",
    "\n",
    "    print('Done scraping WOMENS club rankings.')\n",
    "    driver.quit()\n",
    "    time.sleep(1)\n",
    "    \n",
    "    # Save the data to a pandas DataFrame\n",
    "    df = pd.DataFrame(rows, columns=headers)\n",
    "    df.dropna(subset=['team'], inplace=True)\n",
    "\n",
    "    # Save the DataFrame to an Excel file\n",
    "    excel_filename = 'opta_club_rankings_womens_23112024.xlsx'\n",
    "    df.to_excel(excel_filename, index=False)\n",
    "    print(f'Data saved to {excel_filename}')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    scrape_opta_club_rankings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7ba9d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
