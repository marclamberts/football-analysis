{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dedc3ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/68/mhmqcpdn52943pyql2n4wj440000gn/T/ipykernel_80422/703160491.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Swerve left'][i] = 1\n",
      "/var/folders/68/mhmqcpdn52943pyql2n4wj440000gn/T/ipykernel_80422/703160491.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Swerve right'][i] = 1\n",
      "/var/folders/68/mhmqcpdn52943pyql2n4wj440000gn/T/ipykernel_80422/703160491.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Deflection'][i] = 1\n",
      "/var/folders/68/mhmqcpdn52943pyql2n4wj440000gn/T/ipykernel_80422/703160491.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Keeper touched'][i] = 1\n",
      "/var/folders/68/mhmqcpdn52943pyql2n4wj440000gn/T/ipykernel_80422/703160491.py:112: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Saved shot off target'][i] = 1\n",
      "/var/folders/68/mhmqcpdn52943pyql2n4wj440000gn/T/ipykernel_80422/703160491.py:124: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['High claim'][i] = 1\n",
      "/var/folders/68/mhmqcpdn52943pyql2n4wj440000gn/T/ipykernel_80422/703160491.py:196: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Keeper throw'][i] = 1\n",
      "/var/folders/68/mhmqcpdn52943pyql2n4wj440000gn/T/ipykernel_80422/703160491.py:208: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Goal kick'][i] = 1\n",
      "/var/folders/68/mhmqcpdn52943pyql2n4wj440000gn/T/ipykernel_80422/703160491.py:268: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Caught'][i] = 1\n",
      "/var/folders/68/mhmqcpdn52943pyql2n4wj440000gn/T/ipykernel_80422/703160491.py:280: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Collected'][i] = 1\n",
      "/var/folders/68/mhmqcpdn52943pyql2n4wj440000gn/T/ipykernel_80422/703160491.py:292: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Diving'][i] = 1\n",
      "/var/folders/68/mhmqcpdn52943pyql2n4wj440000gn/T/ipykernel_80422/703160491.py:304: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Standing save'][i] = 1\n",
      "/var/folders/68/mhmqcpdn52943pyql2n4wj440000gn/T/ipykernel_80422/703160491.py:316: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Stooping'][i] = 1\n",
      "/var/folders/68/mhmqcpdn52943pyql2n4wj440000gn/T/ipykernel_80422/703160491.py:340: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Hands'][i] = 1\n",
      "/var/folders/68/mhmqcpdn52943pyql2n4wj440000gn/T/ipykernel_80422/703160491.py:400: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['GK hoof'][i] = 1\n",
      "/var/folders/68/mhmqcpdn52943pyql2n4wj440000gn/T/ipykernel_80422/703160491.py:412: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['GK kick from hands'][i] = 1\n",
      "/var/folders/68/mhmqcpdn52943pyql2n4wj440000gn/T/ipykernel_80422/703160491.py:426: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['GoalMouthY'][i] = mouthy\n",
      "/var/folders/68/mhmqcpdn52943pyql2n4wj440000gn/T/ipykernel_80422/703160491.py:434: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['GoalMouthZ'][i] = mouthz\n",
      "/var/folders/68/mhmqcpdn52943pyql2n4wj440000gn/T/ipykernel_80422/703160491.py:447: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.pass_angle[i] = angle\n",
      "/var/folders/68/mhmqcpdn52943pyql2n4wj440000gn/T/ipykernel_80422/703160491.py:455: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.pass_length[i] = length\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to: data_gk.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = \"/Users/marclambertes/Python/Matches/Men/2024-2025/Premier League 2024-2025/Nottm Forest 1-0 Man City.csv\"  # Replace with your actual file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Rename typeId values\n",
    "type_mapping = {\n",
    "    13: \"Miss\",\n",
    "    14: \"Post\",\n",
    "    15: \"Shot on Target\",\n",
    "    16: \"Goal\"\n",
    "}\n",
    "df[\"typeId\"] = df[\"typeId\"].replace(type_mapping)\n",
    "\n",
    "# Identify qualifier columns\n",
    "type_cols = [col for col in df.columns if '/qualifierId' in col]\n",
    "\n",
    "# Add endX and endY columns\n",
    "df['endX'] = 0.0\n",
    "df['endY'] = 0.0\n",
    "\n",
    "# Assign values for endX and endY based on qualifier IDs\n",
    "for i in range(len(df)):\n",
    "    df1 = df.iloc[i:i+1, :]\n",
    "    \n",
    "    for j, col in enumerate(type_cols):\n",
    "        if df1[col].values[0] == 140:\n",
    "            df.at[i, 'endX'] = df1.loc[:, f'qualifier/{j}/value'].values[0]\n",
    "        elif df1[col].values[0] == 141:\n",
    "            df.at[i, 'endY'] = df1.loc[:, f'qualifier/{j}/value'].values[0]\n",
    "\n",
    "df['Swerve left'] = 0\n",
    "for i in range(len(df)):\n",
    "    df1 = df.iloc[i:i+1,:]\n",
    "    j = 0\n",
    "    for j in range(len(type_cols)):\n",
    "        col = df1[type_cols[j]].values[0]\n",
    "        if col == 120:\n",
    "            df['Swerve left'][i] = 1\n",
    "        else:\n",
    "            j +=1\n",
    "            df.at[i, str(qualifier_value)] = 1  # Mark as 1 if present\n",
    "            \n",
    "df['Swerve right'] = 0\n",
    "for i in range(len(df)):\n",
    "    df1 = df.iloc[i:i+1,:]\n",
    "    j = 0\n",
    "    for j in range(len(type_cols)):\n",
    "        col = df1[type_cols[j]].values[0]\n",
    "        if col == 121:\n",
    "            df['Swerve right'][i] = 1\n",
    "        else:\n",
    "            j +=1\n",
    "            df.at[i, str(qualifier_value)] = 1  # Mark as 1 if present\n",
    "\n",
    "df['Deflection'] = 0\n",
    "for i in range(len(df)):\n",
    "    df1 = df.iloc[i:i+1,:]\n",
    "    j = 0\n",
    "    for j in range(len(type_cols)):\n",
    "        col = df1[type_cols[j]].values[0]\n",
    "        if col == 133:\n",
    "            df['Deflection'][i] = 1\n",
    "        else:\n",
    "            j +=1\n",
    "            df.at[i, str(qualifier_value)] = 1  # Mark as 1 if present\n",
    "            \n",
    "df['Keeper touched'] = 0\n",
    "for i in range(len(df)):\n",
    "    df1 = df.iloc[i:i+1,:]\n",
    "    j = 0\n",
    "    for j in range(len(type_cols)):\n",
    "        col = df1[type_cols[j]].values[0]\n",
    "        if col == 136:\n",
    "            df['Keeper touched'][i] = 1\n",
    "        else:\n",
    "            j +=1\n",
    "            df.at[i, str(qualifier_value)] = 1  # Mark as 1 if present\n",
    "            \n",
    "df['Keeper saved'] = 0\n",
    "for i in range(len(df)):\n",
    "    df1 = df.iloc[i:i+1,:]\n",
    "    j = 0\n",
    "    for j in range(len(type_cols)):\n",
    "        col = df1[type_cols[j]].values[0]\n",
    "        if col == 137:\n",
    "            df['Keeper saved'][i] = 1\n",
    "        else:\n",
    "            j +=1\n",
    "            df.at[i, str(qualifier_value)] = 1  # Mark as 1 if present\n",
    "            \n",
    "df['Block hand'] = 0\n",
    "for i in range(len(df)):\n",
    "    df1 = df.iloc[i:i+1,:]\n",
    "    j = 0\n",
    "    for j in range(len(type_cols)):\n",
    "        col = df1[type_cols[j]].values[0]\n",
    "        if col == 192:\n",
    "            df['Block hand'][i] = 1\n",
    "        else:\n",
    "            j +=1\n",
    "            df.at[i, str(qualifier_value)] = 1  # Mark as 1 if present\n",
    "            \n",
    "df['Saved shot off target'] = 0\n",
    "for i in range(len(df)):\n",
    "    df1 = df.iloc[i:i+1,:]\n",
    "    j = 0\n",
    "    for j in range(len(type_cols)):\n",
    "        col = df1[type_cols[j]].values[0]\n",
    "        if col == 196:\n",
    "            df['Saved shot off target'][i] = 1\n",
    "        else:\n",
    "            j +=1\n",
    "            df.at[i, str(qualifier_value)] = 1  # Mark as 1 if present      \n",
    "            \n",
    "df['High claim'] = 0\n",
    "for i in range(len(df)):\n",
    "    df1 = df.iloc[i:i+1,:]\n",
    "    j = 0\n",
    "    for j in range(len(type_cols)):\n",
    "        col = df1[type_cols[j]].values[0]\n",
    "        if col == 88:\n",
    "            df['High claim'][i] = 1\n",
    "        else:\n",
    "            j +=1\n",
    "            df.at[i, str(qualifier_value)] = 1  # Mark as 1 if present  \n",
    "\n",
    "df['1 on 1'] = 0\n",
    "for i in range(len(df)):\n",
    "    df1 = df.iloc[i:i+1,:]\n",
    "    j = 0\n",
    "    for j in range(len(type_cols)):\n",
    "        col = df1[type_cols[j]].values[0]\n",
    "        if col == 89:\n",
    "            df['1 on 1'][i] = 1\n",
    "        else:\n",
    "            j +=1\n",
    "            df.at[i, str(qualifier_value)] = 1  # Mark as 1 if present   \n",
    "        \n",
    "df['Deflected save'] = 0\n",
    "for i in range(len(df)):\n",
    "    df1 = df.iloc[i:i+1,:]\n",
    "    j = 0\n",
    "    for j in range(len(type_cols)):\n",
    "        col = df1[type_cols[j]].values[0]\n",
    "        if col == 90:\n",
    "            df['Deflected save'][i] = 1\n",
    "        else:\n",
    "            j +=1\n",
    "            df.at[i, str(qualifier_value)] = 1  # Mark as 1 if present   \n",
    "            \n",
    "df['Dive and deflect'] = 0\n",
    "for i in range(len(df)):\n",
    "    df1 = df.iloc[i:i+1,:]\n",
    "    j = 0\n",
    "    for j in range(len(type_cols)):\n",
    "        col = df1[type_cols[j]].values[0]\n",
    "        if col == 91:\n",
    "            df['Dive and deflect'][i] = 1\n",
    "        else:\n",
    "            j +=1\n",
    "            df.at[i, str(qualifier_value)] = 1  # Mark as 1 if present  \n",
    "            \n",
    "df['Catch'] = 0\n",
    "for i in range(len(df)):\n",
    "    df1 = df.iloc[i:i+1,:]\n",
    "    j = 0\n",
    "    for j in range(len(type_cols)):\n",
    "        col = df1[type_cols[j]].values[0]\n",
    "        if col == 92:\n",
    "            df['Catch'][i] = 1\n",
    "        else:\n",
    "            j +=1\n",
    "            df.at[i, str(qualifier_value)] = 1  # Mark as 1 if present \n",
    "            \n",
    "df['Dive and catch'] = 0\n",
    "for i in range(len(df)):\n",
    "    df1 = df.iloc[i:i+1,:]\n",
    "    j = 0\n",
    "    for j in range(len(type_cols)):\n",
    "        col = df1[type_cols[j]].values[0]\n",
    "        if col == 93:\n",
    "            df['Dive and catch'][i] = 1\n",
    "        else:\n",
    "            j +=1\n",
    "            df.at[i, str(qualifier_value)] = 1  # Mark as 1 if present \n",
    "            \n",
    "df['Keeper throw'] = 0\n",
    "for i in range(len(df)):\n",
    "    df1 = df.iloc[i:i+1,:]\n",
    "    j = 0\n",
    "    for j in range(len(type_cols)):\n",
    "        col = df1[type_cols[j]].values[0]\n",
    "        if col == 123:\n",
    "            df['Keeper throw'][i] = 1\n",
    "        else:\n",
    "            j +=1\n",
    "            df.at[i, str(qualifier_value)] = 1  # Mark as 1 if present \n",
    "            \n",
    "df['Goal kick'] = 0\n",
    "for i in range(len(df)):\n",
    "    df1 = df.iloc[i:i+1,:]\n",
    "    j = 0\n",
    "    for j in range(len(type_cols)):\n",
    "        col = df1[type_cols[j]].values[0]\n",
    "        if col == 124:\n",
    "            df['Goal kick'][i] = 1\n",
    "        else:\n",
    "            j +=1\n",
    "            df.at[i, str(qualifier_value)] = 1  # Mark as 1 if present \n",
    "            \n",
    "df['Punch'] = 0\n",
    "for i in range(len(df)):\n",
    "    df1 = df.iloc[i:i+1,:]\n",
    "    j = 0\n",
    "    for j in range(len(type_cols)):\n",
    "        col = df1[type_cols[j]].values[0]\n",
    "        if col == 128:\n",
    "            df['Punch'][i] = 1\n",
    "        else:\n",
    "            j +=1\n",
    "            df.at[i, str(qualifier_value)] = 1  # Mark as 1 if present \n",
    "            \n",
    "df['Parried safe'] = 0\n",
    "for i in range(len(df)):\n",
    "    df1 = df.iloc[i:i+1,:]\n",
    "    j = 0\n",
    "    for j in range(len(type_cols)):\n",
    "        col = df1[type_cols[j]].values[0]\n",
    "        if col == 173:\n",
    "            df['Parried safe'][i] = 1\n",
    "        else:\n",
    "            j +=1\n",
    "            df.at[i, str(qualifier_value)] = 1  # Mark as 1 if present \n",
    "            \n",
    "df['Parried danger'] = 0\n",
    "for i in range(len(df)):\n",
    "    df1 = df.iloc[i:i+1,:]\n",
    "    j = 0\n",
    "    for j in range(len(type_cols)):\n",
    "        col = df1[type_cols[j]].values[0]\n",
    "        if col == 173:\n",
    "            df['Parried danger'][i] = 1\n",
    "        else:\n",
    "            j +=1\n",
    "            df.at[i, str(qualifier_value)] = 1  # Mark as 1 if present \n",
    "            \n",
    "df['Fingertip'] = 0\n",
    "for i in range(len(df)):\n",
    "    df1 = df.iloc[i:i+1,:]\n",
    "    j = 0\n",
    "    for j in range(len(type_cols)):\n",
    "        col = df1[type_cols[j]].values[0]\n",
    "        if col == 175:\n",
    "            df['Fingertip'][i] = 1\n",
    "        else:\n",
    "            j +=1\n",
    "            df.at[i, str(qualifier_value)] = 1  # Mark as 1 if present \n",
    "            \n",
    "df['Caught'] = 0\n",
    "for i in range(len(df)):\n",
    "    df1 = df.iloc[i:i+1,:]\n",
    "    j = 0\n",
    "    for j in range(len(type_cols)):\n",
    "        col = df1[type_cols[j]].values[0]\n",
    "        if col == 176:\n",
    "            df['Caught'][i] = 1\n",
    "        else:\n",
    "            j +=1\n",
    "            df.at[i, str(qualifier_value)] = 1  # Mark as 1 if present \n",
    "            \n",
    "df['Collected'] = 0\n",
    "for i in range(len(df)):\n",
    "    df1 = df.iloc[i:i+1,:]\n",
    "    j = 0\n",
    "    for j in range(len(type_cols)):\n",
    "        col = df1[type_cols[j]].values[0]\n",
    "        if col == 177:\n",
    "            df['Collected'][i] = 1\n",
    "        else:\n",
    "            j +=1\n",
    "            df.at[i, str(qualifier_value)] = 1  # Mark as 1 if present \n",
    "            \n",
    "df['Diving'] = 0\n",
    "for i in range(len(df)):\n",
    "    df1 = df.iloc[i:i+1,:]\n",
    "    j = 0\n",
    "    for j in range(len(type_cols)):\n",
    "        col = df1[type_cols[j]].values[0]\n",
    "        if col == 177:\n",
    "            df['Diving'][i] = 1\n",
    "        else:\n",
    "            j +=1\n",
    "            df.at[i, str(qualifier_value)] = 1  # Mark as 1 if present \n",
    "            \n",
    "df['Standing save'] = 0\n",
    "for i in range(len(df)):\n",
    "    df1 = df.iloc[i:i+1,:]\n",
    "    j = 0\n",
    "    for j in range(len(type_cols)):\n",
    "        col = df1[type_cols[j]].values[0]\n",
    "        if col == 178:\n",
    "            df['Standing save'][i] = 1\n",
    "        else:\n",
    "            j +=1\n",
    "            df.at[i, str(qualifier_value)] = 1  # Mark as 1 if present \n",
    "            \n",
    "df['Stooping'] = 0\n",
    "for i in range(len(df)):\n",
    "    df1 = df.iloc[i:i+1,:]\n",
    "    j = 0\n",
    "    for j in range(len(type_cols)):\n",
    "        col = df1[type_cols[j]].values[0]\n",
    "        if col == 180:\n",
    "            df['Stooping'][i] = 1\n",
    "        else:\n",
    "            j +=1\n",
    "            df.at[i, str(qualifier_value)] = 1  # Mark as 1 if present \n",
    "            \n",
    "df['Reaching'] = 0\n",
    "for i in range(len(df)):\n",
    "    df1 = df.iloc[i:i+1,:]\n",
    "    j = 0\n",
    "    for j in range(len(type_cols)):\n",
    "        col = df1[type_cols[j]].values[0]\n",
    "        if col == 181:\n",
    "            df['Reaching'][i] = 1\n",
    "        else:\n",
    "            j +=1\n",
    "            df.at[i, str(qualifier_value)] = 1  # Mark as 1 if present \n",
    "            \n",
    "df['Hands'] = 0\n",
    "for i in range(len(df)):\n",
    "    df1 = df.iloc[i:i+1,:]\n",
    "    j = 0\n",
    "    for j in range(len(type_cols)):\n",
    "        col = df1[type_cols[j]].values[0]\n",
    "        if col == 182:\n",
    "            df['Hands'][i] = 1\n",
    "        else:\n",
    "            j +=1\n",
    "            df.at[i, str(qualifier_value)] = 1  # Mark as 1 if present \n",
    "                        \n",
    "df['Feet'] = 0\n",
    "for i in range(len(df)):\n",
    "    df1 = df.iloc[i:i+1,:]\n",
    "    j = 0\n",
    "    for j in range(len(type_cols)):\n",
    "        col = df1[type_cols[j]].values[0]\n",
    "        if col == 183:\n",
    "            df['Feet'][i] = 1\n",
    "        else:\n",
    "            j +=1\n",
    "            df.at[i, str(qualifier_value)] = 1  # Mark as 1 if present \n",
    "            \n",
    "df['Scored'] = 0\n",
    "for i in range(len(df)):\n",
    "    df1 = df.iloc[i:i+1,:]\n",
    "    j = 0\n",
    "    for j in range(len(type_cols)):\n",
    "        col = df1[type_cols[j]].values[0]\n",
    "        if col == 186:\n",
    "            df['Scored'][i] = 1\n",
    "        else:\n",
    "            j +=1\n",
    "            df.at[i, str(qualifier_value)] = 1  # Mark as 1 if present \n",
    "            \n",
    "df['Saved'] = 0\n",
    "for i in range(len(df)):\n",
    "    df1 = df.iloc[i:i+1,:]\n",
    "    j = 0\n",
    "    for j in range(len(type_cols)):\n",
    "        col = df1[type_cols[j]].values[0]\n",
    "        if col == 187:\n",
    "            df['Saved'][i] = 1\n",
    "        else:\n",
    "            j +=1\n",
    "            df.at[i, str(qualifier_value)] = 1  # Mark as 1 if present \n",
    "            \n",
    "df['Missed'] = 0\n",
    "for i in range(len(df)):\n",
    "    df1 = df.iloc[i:i+1,:]\n",
    "    j = 0\n",
    "    for j in range(len(type_cols)):\n",
    "        col = df1[type_cols[j]].values[0]\n",
    "        if col == 188:\n",
    "            df['Missed'][i] = 1\n",
    "        else:\n",
    "            j +=1\n",
    "            df.at[i, str(qualifier_value)] = 1  # Mark as 1 if present \n",
    "            \n",
    "df['GK hoof'] = 0\n",
    "for i in range(len(df)):\n",
    "    df1 = df.iloc[i:i+1,:]\n",
    "    j = 0\n",
    "    for j in range(len(type_cols)):\n",
    "        col = df1[type_cols[j]].values[0]\n",
    "        if col == 198:\n",
    "            df['GK hoof'][i] = 1\n",
    "        else:\n",
    "            j +=1\n",
    "            df.at[i, str(qualifier_value)] = 1  # Mark as 1 if present \n",
    "            \n",
    "df['GK kick from hands'] = 0\n",
    "for i in range(len(df)):\n",
    "    df1 = df.iloc[i:i+1,:]\n",
    "    j = 0\n",
    "    for j in range(len(type_cols)):\n",
    "        col = df1[type_cols[j]].values[0]\n",
    "        if col == 198:\n",
    "            df['GK kick from hands'][i] = 1\n",
    "        else:\n",
    "            j +=1\n",
    "            df.at[i, str(qualifier_value)] = 1  # Mark as 1 if present \n",
    "            \n",
    "df['GoalMouthY'] = 0.0\n",
    "df['GoalMouthZ'] = 0.0\n",
    "for i in range(len(df)):            \n",
    "    df1 = df.iloc[i:i+1,:]\n",
    "    j = 0\n",
    "    for j in range(len(type_cols)):\n",
    "        col = df1[type_cols[j]].values[0]\n",
    "        if col == 102:\n",
    "            mouthy = df1.loc[:,'qualifier/%i/value' %j].values[0]\n",
    "            df['GoalMouthY'][i] = mouthy\n",
    "        else:\n",
    "            j +=1\n",
    "    k = 0\n",
    "    for k in range(len(type_cols)):\n",
    "        col = df1[type_cols[k]].values[0]\n",
    "        if col == 103:\n",
    "            mouthz = df1.loc[:,'qualifier/%i/value' %k].values[0]\n",
    "            df['GoalMouthZ'][i] = mouthz\n",
    "        else:\n",
    "            k +=1\n",
    "            \n",
    "df['pass_angle'] = 0.0\n",
    "df['pass_length'] = 0.0\n",
    "for i in range(len(df)):\n",
    "    df1 = df.iloc[i:i+1,:]\n",
    "    j = 0\n",
    "    for j in range(len(type_cols)):\n",
    "        col = df1[type_cols[j]].values[0]\n",
    "        if col == 213:\n",
    "            angle = df1.loc[:,'qualifier/%i/value' %j].values[0]\n",
    "            df.pass_angle[i] = angle\n",
    "        else:\n",
    "            j +=1\n",
    "    k = 0\n",
    "    for k in range(len(type_cols)):\n",
    "        col = df1[type_cols[k]].values[0]\n",
    "        if col == 212:\n",
    "            length = df1.loc[:,'qualifier/%i/value' %k].values[0]\n",
    "            df.pass_length[i] = length\n",
    "        else:\n",
    "            k +=1\n",
    "            \n",
    "# Save the updated DataFrame to an Excel file\n",
    "output_file_path = \"data_gk.xlsx\"\n",
    "df.to_excel(output_file_path, index=False)\n",
    "\n",
    "print(f\"Processed data saved to: {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "295b8c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marclambertes/anaconda3/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ xSave predictions saved to xSave_Predictions.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marclambertes/anaconda3/lib/python3.10/site-packages/sklearn/base.py:420: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"data_gk.xlsx\"  # Update with actual path\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Remove duplicate columns if any\n",
    "df = df.loc[:, ~df.columns.duplicated()]\n",
    "\n",
    "# Keep only rows where 'typeId' is a shot type\n",
    "valid_shots = [\"Miss\", \"Post\", \"Shot on Target\", \"Goal\"]\n",
    "df = df[df['typeId'].isin(valid_shots)]\n",
    "\n",
    "# Stop execution if dataset is empty after filtering\n",
    "if df.empty:\n",
    "    raise ValueError(\"❌ ERROR: No valid shot data found! Check 'typeId' values.\")\n",
    "\n",
    "# ---------------------------\n",
    "# STEP 1: ONE-HOT ENCODE typeId (Shot Type)\n",
    "# ---------------------------\n",
    "encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "shot_encoded = encoder.fit_transform(df[['typeId']])\n",
    "\n",
    "# Convert encoded shots to DataFrame\n",
    "shot_encoded_df = pd.DataFrame(shot_encoded, columns=encoder.get_feature_names_out(['typeId']))\n",
    "\n",
    "# Merge with original dataset\n",
    "df = pd.concat([df, shot_encoded_df], axis=1)\n",
    "\n",
    "# Drop original 'typeId' column\n",
    "df.drop(columns=['typeId'], inplace=True)\n",
    "\n",
    "# Define relevant features\n",
    "features = list(encoder.get_feature_names_out(['typeId'])) + [\n",
    "    'GoalMouthY', 'GoalMouthZ', 'pass_angle', 'pass_length', \n",
    "    'Swerve left', 'Swerve right', 'Deflection', 'Keeper touched', \n",
    "    '1 on 1', 'Block hand', 'Saved shot off target', 'High claim', 'Deflected save'\n",
    "]\n",
    "\n",
    "# Ensure required features exist\n",
    "available_features = [col for col in features if col in df.columns]\n",
    "df_filtered = df[available_features].copy()\n",
    "\n",
    "# Handle missing values by filling them with median values\n",
    "df_filtered.fillna(df_filtered.median(), inplace=True)\n",
    "\n",
    "# Stop execution if dataset is empty after filtering\n",
    "if df_filtered.empty:\n",
    "    raise ValueError(\"❌ ERROR: Data is empty after feature selection! Check missing values.\")\n",
    "\n",
    "# ---------------------------\n",
    "# STEP 2: CLUSTER SHOTS TO ESTIMATE DIFFICULTY\n",
    "# ---------------------------\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df_filtered)\n",
    "\n",
    "# Apply PCA for dimensionality reduction\n",
    "pca = PCA(n_components=3)  # Reduce to 3 key features\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Use K-Means to cluster shots by difficulty\n",
    "kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)  # Clusters: Easy, Medium, Hard\n",
    "df_filtered['Shot_Difficulty'] = kmeans.fit_predict(X_pca)\n",
    "\n",
    "# Normalize difficulty scores (0 = easy, 1 = medium, 2 = hard → scale to 0-1)\n",
    "df_filtered['Shot_Difficulty'] = df_filtered['Shot_Difficulty'] / 2.0\n",
    "\n",
    "# ---------------------------\n",
    "# STEP 3: TRAIN REGRESSION MODEL TO PREDICT xSAVE\n",
    "# ---------------------------\n",
    "X_train = df_filtered.drop(columns=['Shot_Difficulty'])\n",
    "y_train = df_filtered['Shot_Difficulty']\n",
    "\n",
    "# Train a regression model to predict expected save probability\n",
    "regressor = RandomForestRegressor(n_estimators=200, max_depth=10, random_state=42)\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# ---------------------------\n",
    "# STEP 4: APPLY MODEL TO DUMMY SHOTS\n",
    "# ---------------------------\n",
    "dummy_shots = pd.DataFrame({\n",
    "    'typeId': np.random.choice([\"Miss\", \"Post\", \"Shot on Target\", \"Goal\"], 10),\n",
    "    'GoalMouthY': np.random.uniform(0, 8, 10),  # Goal area Y\n",
    "    'GoalMouthZ': np.random.uniform(0, 2, 10),  # Goal height\n",
    "    'pass_angle': np.random.uniform(-3.14, 3.14, 10),  # Angle in radians\n",
    "    'pass_length': np.random.uniform(5, 40, 10),  # Shot distance\n",
    "    'Swerve left': np.random.choice([0, 1], 10),\n",
    "    'Swerve right': np.random.choice([0, 1], 10),\n",
    "    'Deflection': np.random.choice([0, 1], 10),\n",
    "    'Keeper touched': np.random.choice([0, 1], 10),\n",
    "    '1 on 1': np.random.choice([0, 1], 10),\n",
    "    'Block hand': np.random.choice([0, 1], 10),\n",
    "    'Saved shot off target': np.random.choice([0, 1], 10),\n",
    "    'High claim': np.random.choice([0, 1], 10),\n",
    "    'Deflected save': np.random.choice([0, 1], 10)\n",
    "})\n",
    "\n",
    "# One-hot encode dummy shots\n",
    "dummy_shots_encoded = encoder.transform(dummy_shots[['typeId']])\n",
    "dummy_shots_df = pd.DataFrame(dummy_shots_encoded, columns=encoder.get_feature_names_out(['typeId']))\n",
    "\n",
    "# Merge with dummy shots DataFrame\n",
    "dummy_shots = pd.concat([dummy_shots, dummy_shots_df], axis=1)\n",
    "\n",
    "# Drop original typeId column\n",
    "dummy_shots.drop(columns=['typeId'], inplace=True)\n",
    "\n",
    "# Ensure dummy shot columns match training features (fixes feature mismatch error)\n",
    "for col in features:\n",
    "    if col not in dummy_shots:\n",
    "        dummy_shots[col] = 0  # Add missing columns with default value\n",
    "\n",
    "# Sort columns to match model training order\n",
    "dummy_shots = dummy_shots[features]\n",
    "\n",
    "# Standardize dummy shot data\n",
    "dummy_shots_scaled = scaler.transform(dummy_shots)\n",
    "\n",
    "# Predict xSave probability for each dummy shot\n",
    "dummy_shots['xSave_Probability'] = regressor.predict(dummy_shots_scaled)\n",
    "\n",
    "# ---------------------------\n",
    "# STEP 5: SAVE TO EXCEL\n",
    "# ---------------------------\n",
    "output_file_path = \"xSave_Predictions.xlsx\"\n",
    "dummy_shots.to_excel(output_file_path, index=False)\n",
    "\n",
    "print(f\"✅ xSave predictions saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "0a62fa92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marclambertes/anaconda3/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Variable Distribution:\n",
      "1    391260\n",
      "0       672\n",
      "Name: Target, dtype: int64\n",
      "Feature Columns:\n",
      "Index(['typeId_1', 'typeId_2', 'typeId_3', 'typeId_4', 'typeId_5', 'typeId_6',\n",
      "       'typeId_7', 'typeId_8', 'typeId_10', 'typeId_11', 'typeId_12',\n",
      "       'typeId_13', 'typeId_14', 'typeId_15', 'typeId_17', 'typeId_18',\n",
      "       'typeId_19', 'typeId_20', 'typeId_24', 'typeId_27', 'typeId_28',\n",
      "       'typeId_30', 'typeId_32', 'typeId_34', 'typeId_37', 'typeId_40',\n",
      "       'typeId_41', 'typeId_42', 'typeId_43', 'typeId_44', 'typeId_45',\n",
      "       'typeId_49', 'typeId_50', 'typeId_51', 'typeId_52', 'typeId_54',\n",
      "       'typeId_55', 'typeId_56', 'typeId_57', 'typeId_58', 'typeId_59',\n",
      "       'typeId_60', 'typeId_61', 'typeId_64', 'typeId_65', 'typeId_68',\n",
      "       'typeId_70', 'typeId_71', 'typeId_74', 'typeId_75', 'typeId_76',\n",
      "       'typeId_80', 'typeId_81', 'typeId_83', 'typeId_84', 'GoalMouthY',\n",
      "       'GoalMouthZ', 'Keeper touched', 'Keeper saved', 'Block hand',\n",
      "       'Saved shot off target', 'High claim', '1 on 1', 'Deflected save',\n",
      "       'Dive and deflect', 'Catch', 'Dive and catch', 'Parried safe',\n",
      "       'Parried danger', 'Fingertip', 'Caught', 'Collected', 'Diving',\n",
      "       'Standing save', 'Stooping', 'Reaching', 'Hands', 'Feet', 'Scored',\n",
      "       'Saved', 'Missed', 'x', 'y'],\n",
      "      dtype='object')\n",
      "✅ Model trained!\n",
      "Mean Squared Error: 0.0014\n",
      "ROC-AUC Score: 1.0000\n",
      "Precision-Recall AUC: 1.0000\n",
      "Range of Predicted Values:\n",
      "Min: 0.0073, Max: 0.9978\n",
      "✅ Model, scaler, and encoder saved to disk.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score, precision_recall_curve, auc\n",
    "import joblib\n",
    "\n",
    "# ---------------------------\n",
    "# STEP 1: LOAD MULTIPLE CSV FILES\n",
    "# ---------------------------\n",
    "folder_path = \"/Users/marclambertes/Python/Matches/Men/2024-2025/Eredivisie 2024-2025/\"  # Update this\n",
    "all_files = glob.glob(folder_path + \"*.csv\")  # Get all CSV files in the folder\n",
    "\n",
    "# Load and combine all files\n",
    "df_list = []\n",
    "for file in all_files:\n",
    "    df_temp = pd.read_csv(file)\n",
    "    if 'typeId' in df_temp.columns:\n",
    "        df_list.append(df_temp)\n",
    "    else:\n",
    "        print(f\"⚠ Skipping {file}: 'typeId' column not found\")\n",
    "\n",
    "# Concatenate all dataframes\n",
    "if df_list:\n",
    "    df = pd.concat(df_list, ignore_index=True)\n",
    "else:\n",
    "    raise ValueError(\"❌ ERROR: No valid shot data found! Check 'typeId' values in your CSV files.\")\n",
    "\n",
    "# ---------------------------\n",
    "# STEP 2: EXTRACT QUALIFIERS AND COORDINATES\n",
    "# ---------------------------\n",
    "\n",
    "# Identify qualifier columns\n",
    "type_cols = [col for col in df.columns if '/qualifierId' in col]\n",
    "\n",
    "# Initialize columns\n",
    "df[\"GoalMouthY\"] = 0.0\n",
    "df[\"GoalMouthZ\"] = 0.0\n",
    "df[\"pass_angle\"] = 0.0\n",
    "df[\"pass_length\"] = 0.0\n",
    "\n",
    "# List of relevant qualifiers to track\n",
    "qualifier_map = {\n",
    "    102: \"GoalMouthY\",\n",
    "    103: \"GoalMouthZ\",\n",
    "    136: \"Keeper touched\",\n",
    "    137: \"Keeper saved\",\n",
    "    192: \"Block hand\",\n",
    "    196: \"Saved shot off target\",\n",
    "    88: \"High claim\",\n",
    "    89: \"1 on 1\",\n",
    "    90: \"Deflected save\",\n",
    "    91: \"Dive and deflect\",\n",
    "    92: \"Catch\",\n",
    "    93: \"Dive and catch\",\n",
    "    173: \"Parried safe\",\n",
    "    174: \"Parried danger\",\n",
    "    175: \"Fingertip\",\n",
    "    176: \"Caught\",\n",
    "    177: \"Collected\",\n",
    "    178: \"Diving\",\n",
    "    179: \"Standing save\",\n",
    "    180: \"Stooping\",\n",
    "    181: \"Reaching\",\n",
    "    182: \"Hands\",\n",
    "    183: \"Feet\",\n",
    "    186: \"Scored\",\n",
    "    187: \"Saved\",\n",
    "    188: \"Missed\",\n",
    "}\n",
    "\n",
    "# Initialize all qualifier-based columns with default values\n",
    "for col_name in qualifier_map.values():\n",
    "    df[col_name] = 0 if \"GoalMouthY\" not in col_name and \"GoalMouthZ\" not in col_name else 0.0\n",
    "\n",
    "# Extract values from qualifiers\n",
    "for i, row in df.iterrows():\n",
    "    for j, col in enumerate(type_cols):\n",
    "        qualifier_value = row[col]\n",
    "        if qualifier_value in qualifier_map:\n",
    "            column_name = qualifier_map[qualifier_value]\n",
    "            if column_name in [\"GoalMouthY\", \"GoalMouthZ\", \"pass_angle\", \"pass_length\"]:\n",
    "                df.at[i, column_name] = row.get(f\"qualifier/{j}/value\", 0.0)\n",
    "            else:\n",
    "                df.at[i, column_name] = 1  # Binary indicators\n",
    "\n",
    "# Extract x and y coordinates\n",
    "df['x'] = df['x'].fillna(0.0)  # Replace missing x values with 0.0\n",
    "df['y'] = df['y'].fillna(0.0)  # Replace missing y values with 0.0\n",
    "\n",
    "# Replace NaN values with 0 for safety\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "# ---------------------------\n",
    "# STEP 3: ONE-HOT ENCODE typeId (Shot Type)\n",
    "# ---------------------------\n",
    "encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "shot_encoded = encoder.fit_transform(df[['typeId']])\n",
    "shot_encoded_df = pd.DataFrame(shot_encoded, columns=encoder.get_feature_names_out(['typeId']))\n",
    "df = pd.concat([df, shot_encoded_df], axis=1)\n",
    "df.drop(columns=['typeId'], inplace=True)\n",
    "\n",
    "# Define relevant features\n",
    "features = list(encoder.get_feature_names_out(['typeId'])) + list(qualifier_map.values()) + ['x', 'y']\n",
    "\n",
    "# Ensure required features exist\n",
    "available_features = [col for col in features if col in df.columns]\n",
    "df_filtered = df[available_features].copy()\n",
    "\n",
    "# ---------------------------\n",
    "# STEP 4: TRAIN THE MODEL\n",
    "# ---------------------------\n",
    "\n",
    "# Create target variable: 1 for saved shots, 0 for goals\n",
    "df_filtered['Target'] = np.where(df['typeId_16'] == 1, 0, 1)  # Use typeId == 16 for goals\n",
    "\n",
    "# Debug: Print the distribution of the target variable\n",
    "print(\"Target Variable Distribution:\")\n",
    "print(df_filtered['Target'].value_counts())\n",
    "\n",
    "# Drop 'typeId_16' from features to avoid data leakage\n",
    "if 'typeId_16' in df_filtered.columns:\n",
    "    df_filtered.drop(columns=['typeId_16'], inplace=True)\n",
    "\n",
    "# Split data into training and testing sets (shuffle the data)\n",
    "X = df_filtered.drop(columns=['Target'])\n",
    "y = df_filtered['Target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "# Debug: Print feature columns\n",
    "print(\"Feature Columns:\")\n",
    "print(X.columns)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train RandomForestClassifier with class weights\n",
    "class_weights = {0: 391260 / 672, 1: 1.0}  # Adjust weights to balance classes\n",
    "regressor = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42, class_weight=class_weights)\n",
    "regressor.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = regressor.predict_proba(X_test_scaled)[:, 1]  # Use predict_proba for probabilities\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred)\n",
    "pr_auc = auc(recall, precision)\n",
    "\n",
    "print(f\"✅ Model trained!\")\n",
    "print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "print(f\"ROC-AUC Score: {roc_auc:.4f}\")\n",
    "print(f\"Precision-Recall AUC: {pr_auc:.4f}\")\n",
    "\n",
    "# Debug: Print the range of predicted values\n",
    "print(\"Range of Predicted Values:\")\n",
    "print(f\"Min: {np.min(y_pred):.4f}, Max: {np.max(y_pred):.4f}\")\n",
    "\n",
    "# Save the model and scaler for future use\n",
    "joblib.dump(regressor, \"xSave_model.pkl\")\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "joblib.dump(encoder, \"encoder.pkl\")\n",
    "print(\"✅ Model, scaler, and encoder saved to disk.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "54c8331e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goalkeepers for each team: {'1fttb31hnskynpku8qd09yhm8': 'N. Bakker', '4tic29sox7m39fy1ztgv0jsiq': 'L. Unnerstall'}\n",
      "Preprocessed Data (First 5 Rows):\n",
      "   typeId_1  typeId_2  typeId_3  typeId_4  typeId_5  typeId_6  typeId_7  \\\n",
      "0       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "1       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "2       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "3       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "4       1.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "\n",
      "   typeId_8  typeId_10  typeId_11  ...  Standing save  Stooping  Reaching  \\\n",
      "0       0.0        0.0        0.0  ...              0         0         0   \n",
      "1       0.0        0.0        0.0  ...              0         0         0   \n",
      "2       0.0        0.0        0.0  ...              0         0         0   \n",
      "3       0.0        0.0        0.0  ...              0         0         0   \n",
      "4       0.0        0.0        0.0  ...              0         0         0   \n",
      "\n",
      "   Hands  Feet  Scored  Saved  Missed     x     y  \n",
      "0      0     0       0      0       0   0.0   0.0  \n",
      "1      0     0       0      0       0   0.0   0.0  \n",
      "2      0     0       0      0       0   0.0   0.0  \n",
      "3      0     0       0      0       0   0.0   0.0  \n",
      "4      0     0       0      0       0  50.2  50.1  \n",
      "\n",
      "[5 rows x 83 columns]\n",
      "✅ xSave values and shot probabilities saved to output_shot_data_with_probability.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load the saved model, scaler, and encoder\n",
    "regressor = joblib.load(\"xSave_model.pkl\")\n",
    "scaler = joblib.load(\"scaler.pkl\")\n",
    "encoder = joblib.load(\"encoder.pkl\")\n",
    "\n",
    "# Define the qualifier mapping\n",
    "qualifier_map = {\n",
    "    102: \"GoalMouthY\",\n",
    "    103: \"GoalMouthZ\",\n",
    "    136: \"Keeper touched\",\n",
    "    137: \"Keeper saved\",\n",
    "    192: \"Block hand\",\n",
    "    196: \"Saved shot off target\",\n",
    "    88: \"High claim\",\n",
    "    89: \"1 on 1\",\n",
    "    90: \"Deflected save\",\n",
    "    91: \"Dive and deflect\",\n",
    "    92: \"Catch\",\n",
    "    93: \"Dive and catch\",\n",
    "    173: \"Parried safe\",\n",
    "    174: \"Parried danger\",\n",
    "    175: \"Fingertip\",\n",
    "    176: \"Caught\",\n",
    "    177: \"Collected\",\n",
    "    178: \"Diving\",\n",
    "    179: \"Standing save\",\n",
    "    180: \"Stooping\",\n",
    "    181: \"Reaching\",\n",
    "    182: \"Hands\",\n",
    "    183: \"Feet\",\n",
    "    186: \"Scored\",\n",
    "    187: \"Saved\",\n",
    "    188: \"Missed\",\n",
    "}\n",
    "\n",
    "# Function to preprocess the shot data\n",
    "def preprocess_shot_data(df):\n",
    "    \"\"\"\n",
    "    Preprocess the shot data by extracting qualifiers and creating relevant features.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The raw shot data loaded from the CSV file.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: The preprocessed shot data with features ready for the model.\n",
    "    \"\"\"\n",
    "    # Identify qualifier columns\n",
    "    type_cols = [col for col in df.columns if '/qualifierId' in col]\n",
    "    \n",
    "    # Initialize columns for qualifier-based features\n",
    "    for col_name in qualifier_map.values():\n",
    "        df[col_name] = 0 if \"GoalMouthY\" not in col_name and \"GoalMouthZ\" not in col_name else 0.0\n",
    "    \n",
    "    # Extract values from qualifiers\n",
    "    for i in range(len(df)):\n",
    "        df1 = df.iloc[i:i+1, :]\n",
    "        for j, col in enumerate(type_cols):\n",
    "            qualifier_value = df1[col].values[0]\n",
    "            if qualifier_value in qualifier_map:\n",
    "                column_name = qualifier_map[qualifier_value]\n",
    "                if column_name in [\"GoalMouthY\", \"GoalMouthZ\"]:\n",
    "                    # Extract the value from the qualifier\n",
    "                    value = df1.get(f\"qualifier/{j}/value\", 0.0)\n",
    "                    if isinstance(value, (np.ndarray, pd.Series)):\n",
    "                        value = value.iloc[0] if len(value) > 0 else 0.0  # Extract scalar value if it's an array or series\n",
    "                    df.at[i, column_name] = float(value)  # Ensure the value is a scalar\n",
    "                else:\n",
    "                    df.at[i, column_name] = 1  # Binary indicators\n",
    "    \n",
    "    # Ensure 'x' and 'y' columns exist\n",
    "    if 'x' not in df.columns:\n",
    "        df['x'] = 0.0  # Default value if missing\n",
    "    if 'y' not in df.columns:\n",
    "        df['y'] = 0.0  # Default value if missing\n",
    "    \n",
    "    # One-hot encode the shot type\n",
    "    if 'typeId' in df.columns:\n",
    "        shot_encoded = encoder.transform(df[['typeId']])\n",
    "        shot_encoded_df = pd.DataFrame(shot_encoded, columns=encoder.get_feature_names_out(['typeId']))\n",
    "        df = pd.concat([df, shot_encoded_df], axis=1)\n",
    "        df.drop(columns=['typeId'], inplace=True)\n",
    "    else:\n",
    "        print(\"⚠ 'typeId' column not found. Skipping one-hot encoding.\")\n",
    "        shot_encoded_df = pd.DataFrame()  # Empty DataFrame\n",
    "    \n",
    "    # Ensure the dataframe has the same features as the training data\n",
    "    features = list(encoder.get_feature_names_out(['typeId'])) + list(qualifier_map.values()) + ['x', 'y']\n",
    "    available_features = [col for col in features if col in df.columns]\n",
    "    df_filtered = df[available_features].copy()\n",
    "    \n",
    "    # Drop 'typeId_16' if it exists\n",
    "    if 'typeId_16' in df_filtered.columns:\n",
    "        df_filtered.drop(columns=['typeId_16'], inplace=True)\n",
    "    \n",
    "    return df_filtered\n",
    "\n",
    "# Function to predict xSave for a preprocessed shot\n",
    "def predict_xSave(df_filtered):\n",
    "    \"\"\"\n",
    "    Predict the xSave value for preprocessed shot data.\n",
    "    \n",
    "    Parameters:\n",
    "    df_filtered (pd.DataFrame): The preprocessed shot data.\n",
    "    \n",
    "    Returns:\n",
    "    np.ndarray: The predicted xSave values (probabilities).\n",
    "    \"\"\"\n",
    "    # Handle missing values (impute with mean)\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    df_imputed = pd.DataFrame(imputer.fit_transform(df_filtered), columns=df_filtered.columns)\n",
    "    \n",
    "    # Scale the features\n",
    "    df_scaled = scaler.transform(df_imputed)\n",
    "    \n",
    "    # Predict the xSave probabilities\n",
    "    xSave_probabilities = regressor.predict_proba(df_scaled)[:, 1]  # Use predict_proba for probabilities\n",
    "    return xSave_probabilities\n",
    "\n",
    "# Function to identify the goalkeeper for each team\n",
    "def identify_goalkeeper(df):\n",
    "    \"\"\"\n",
    "    Identify the goalkeeper for each team as the player with the lowest average x for typeId == 1.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The raw shot data loaded from the CSV file.\n",
    "    \n",
    "    Returns:\n",
    "    dict: A dictionary mapping team IDs to goalkeeper names.\n",
    "    \"\"\"\n",
    "    # Filter rows where typeId == 1 (assumed to be goalkeeper-related events)\n",
    "    goalkeeper_events = df[df['typeId'] == 1]\n",
    "    \n",
    "    # Calculate the average x for each player\n",
    "    player_avg_x = goalkeeper_events.groupby(['contestantId', 'playerName'])['x'].mean().reset_index()\n",
    "    \n",
    "    # Find the player with the lowest average x for each team\n",
    "    team_goalkeeper_map = {}\n",
    "    for team_id, group in player_avg_x.groupby('contestantId'):\n",
    "        goalkeeper_row = group.loc[group['x'].idxmin()]\n",
    "        team_goalkeeper_map[team_id] = goalkeeper_row['playerName']\n",
    "    \n",
    "    return team_goalkeeper_map\n",
    "\n",
    "# Load shot data from a CSV file\n",
    "csv_file_path = \"/Users/marclambertes/Python/Matches/Men/2024-2025/Eredivisie 2024-2025/Twente 1-0 Almere.csv\"  # Update this path\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Get the goalkeepers' names for both teams\n",
    "team_goalkeeper_map = identify_goalkeeper(df)\n",
    "print(f\"Goalkeepers for each team: {team_goalkeeper_map}\")\n",
    "\n",
    "# Preprocess the entire dataset\n",
    "df_filtered = preprocess_shot_data(df)\n",
    "\n",
    "# Debug: Print the first few rows of the preprocessed data\n",
    "print(\"Preprocessed Data (First 5 Rows):\")\n",
    "print(df_filtered.head())\n",
    "\n",
    "# Predict xSave probabilities for all rows\n",
    "xSave_probabilities = predict_xSave(df_filtered)\n",
    "\n",
    "# Add the predicted xSave probabilities to the original dataframe\n",
    "df['xSave'] = xSave_probabilities\n",
    "\n",
    "# Assign the correct goalkeeper's name to each shot\n",
    "def get_opposing_goalkeeper(row, team_goalkeeper_map):\n",
    "    \"\"\"\n",
    "    Get the opposing goalkeeper's name for a given shot.\n",
    "    \n",
    "    Parameters:\n",
    "    row (pd.Series): A row from the DataFrame representing a shot.\n",
    "    team_goalkeeper_map (dict): A dictionary mapping team IDs to goalkeeper names.\n",
    "    \n",
    "    Returns:\n",
    "    str: The name of the opposing goalkeeper.\n",
    "    \"\"\"\n",
    "    # Get the team ID for the shot\n",
    "    team_id = row['contestantId']\n",
    "    \n",
    "    # Find the opposing team's goalkeeper\n",
    "    for t_id, goalkeeper_name in team_goalkeeper_map.items():\n",
    "        if t_id != team_id:\n",
    "            return goalkeeper_name\n",
    "    \n",
    "    return \"Unknown\"  # Default if no opposing goalkeeper is found\n",
    "\n",
    "# Create a new DataFrame with the desired columns\n",
    "output_df = pd.DataFrame({\n",
    "    'playerName': df.apply(lambda row: get_opposing_goalkeeper(row, team_goalkeeper_map), axis=1),  # Name of the opposing goalkeeper\n",
    "    'Team': df['contestantId'],\n",
    "    'typeId': df['typeId'],  # Type of shot (13, 14, 15, 16)\n",
    "    'x': df['x'],  # X coordinate of the shot\n",
    "    'y': df['y'],  # Y coordinate of the shot\n",
    "    'GoalMouthY': df['GoalMouthY'],  # GoalMouthY from qualifiers\n",
    "    'GoalMouthZ': df['GoalMouthZ'],  # GoalMouthZ from qualifiers\n",
    "    'xSave': df['xSave']  # Predicted xSave probability\n",
    "})\n",
    "\n",
    "# Filter rows to include only shots (typeId 13, 14, 15, 16)\n",
    "output_df = output_df[output_df['typeId'].isin([13, 14, 15, 16])]\n",
    "\n",
    "# Save the results to a new Excel file\n",
    "output_excel_path = \"output_shot_data_with_probability.xlsx\"  # Update this path\n",
    "output_df.to_excel(output_excel_path, index=False)\n",
    "\n",
    "print(f\"✅ xSave values and shot probabilities saved to {output_excel_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f0bb42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
