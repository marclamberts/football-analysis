{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dedc3ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/68/mhmqcpdn52943pyql2n4wj440000gn/T/ipykernel_80422/703160491.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Swerve left'][i] = 1\n",
      "/var/folders/68/mhmqcpdn52943pyql2n4wj440000gn/T/ipykernel_80422/703160491.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Swerve right'][i] = 1\n",
      "/var/folders/68/mhmqcpdn52943pyql2n4wj440000gn/T/ipykernel_80422/703160491.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Deflection'][i] = 1\n",
      "/var/folders/68/mhmqcpdn52943pyql2n4wj440000gn/T/ipykernel_80422/703160491.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Keeper touched'][i] = 1\n",
      "/var/folders/68/mhmqcpdn52943pyql2n4wj440000gn/T/ipykernel_80422/703160491.py:112: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Saved shot off target'][i] = 1\n",
      "/var/folders/68/mhmqcpdn52943pyql2n4wj440000gn/T/ipykernel_80422/703160491.py:124: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['High claim'][i] = 1\n",
      "/var/folders/68/mhmqcpdn52943pyql2n4wj440000gn/T/ipykernel_80422/703160491.py:196: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Keeper throw'][i] = 1\n",
      "/var/folders/68/mhmqcpdn52943pyql2n4wj440000gn/T/ipykernel_80422/703160491.py:208: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Goal kick'][i] = 1\n",
      "/var/folders/68/mhmqcpdn52943pyql2n4wj440000gn/T/ipykernel_80422/703160491.py:268: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Caught'][i] = 1\n",
      "/var/folders/68/mhmqcpdn52943pyql2n4wj440000gn/T/ipykernel_80422/703160491.py:280: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Collected'][i] = 1\n",
      "/var/folders/68/mhmqcpdn52943pyql2n4wj440000gn/T/ipykernel_80422/703160491.py:292: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Diving'][i] = 1\n",
      "/var/folders/68/mhmqcpdn52943pyql2n4wj440000gn/T/ipykernel_80422/703160491.py:304: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Standing save'][i] = 1\n",
      "/var/folders/68/mhmqcpdn52943pyql2n4wj440000gn/T/ipykernel_80422/703160491.py:316: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Stooping'][i] = 1\n",
      "/var/folders/68/mhmqcpdn52943pyql2n4wj440000gn/T/ipykernel_80422/703160491.py:340: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Hands'][i] = 1\n",
      "/var/folders/68/mhmqcpdn52943pyql2n4wj440000gn/T/ipykernel_80422/703160491.py:400: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['GK hoof'][i] = 1\n",
      "/var/folders/68/mhmqcpdn52943pyql2n4wj440000gn/T/ipykernel_80422/703160491.py:412: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['GK kick from hands'][i] = 1\n",
      "/var/folders/68/mhmqcpdn52943pyql2n4wj440000gn/T/ipykernel_80422/703160491.py:426: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['GoalMouthY'][i] = mouthy\n",
      "/var/folders/68/mhmqcpdn52943pyql2n4wj440000gn/T/ipykernel_80422/703160491.py:434: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['GoalMouthZ'][i] = mouthz\n",
      "/var/folders/68/mhmqcpdn52943pyql2n4wj440000gn/T/ipykernel_80422/703160491.py:447: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.pass_angle[i] = angle\n",
      "/var/folders/68/mhmqcpdn52943pyql2n4wj440000gn/T/ipykernel_80422/703160491.py:455: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.pass_length[i] = length\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to: data_gk.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = \"/Users/marclambertes/Python/Matches/Men/2024-2025/Premier League 2024-2025/Nottm Forest 1-0 Man City.csv\"  # Replace with your actual file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Rename typeId values\n",
    "type_mapping = {\n",
    "    13: \"Miss\",\n",
    "    14: \"Post\",\n",
    "    15: \"Shot on Target\",\n",
    "    16: \"Goal\"\n",
    "}\n",
    "df[\"typeId\"] = df[\"typeId\"].replace(type_mapping)\n",
    "\n",
    "# Identify qualifier columns\n",
    "type_cols = [col for col in df.columns if '/qualifierId' in col]\n",
    "\n",
    "# Add endX and endY columns\n",
    "df['endX'] = 0.0\n",
    "df['endY'] = 0.0\n",
    "\n",
    "# Assign values for endX and endY based on qualifier IDs\n",
    "for i in range(len(df)):\n",
    "    df1 = df.iloc[i:i+1, :]\n",
    "    \n",
    "    for j, col in enumerate(type_cols):\n",
    "        if df1[col].values[0] == 140:\n",
    "            df.at[i, 'endX'] = df1.loc[:, f'qualifier/{j}/value'].values[0]\n",
    "        elif df1[col].values[0] == 141:\n",
    "            df.at[i, 'endY'] = df1.loc[:, f'qualifier/{j}/value'].values[0]\n",
    "\n",
    "df['Swerve left'] = 0\n",
    "for i in range(len(df)):\n",
    "    df1 = df.iloc[i:i+1,:]\n",
    "    j = 0\n",
    "    for j in range(len(type_cols)):\n",
    "        col = df1[type_cols[j]].values[0]\n",
    "        if col == 120:\n",
    "            df['Swerve left'][i] = 1\n",
    "        else:\n",
    "            j +=1\n",
    "            df.at[i, str(qualifier_value)] = 1  # Mark as 1 if present\n",
    "            \n",
    "df['Swerve right'] = 0\n",
    "for i in range(len(df)):\n",
    "    df1 = df.iloc[i:i+1,:]\n",
    "    j = 0\n",
    "    for j in range(len(type_cols)):\n",
    "        col = df1[type_cols[j]].values[0]\n",
    "        if col == 121:\n",
    "            df['Swerve right'][i] = 1\n",
    "        else:\n",
    "            j +=1\n",
    "            df.at[i, str(qualifier_value)] = 1  # Mark as 1 if present\n",
    "\n",
    "df['Deflection'] = 0\n",
    "for i in range(len(df)):\n",
    "    df1 = df.iloc[i:i+1,:]\n",
    "    j = 0\n",
    "    for j in range(len(type_cols)):\n",
    "        col = df1[type_cols[j]].values[0]\n",
    "        if col == 133:\n",
    "            df['Deflection'][i] = 1\n",
    "        else:\n",
    "            j +=1\n",
    "            df.at[i, str(qualifier_value)] = 1  # Mark as 1 if present\n",
    "            \n",
    "df['Keeper touched'] = 0\n",
    "for i in range(len(df)):\n",
    "    df1 = df.iloc[i:i+1,:]\n",
    "    j = 0\n",
    "    for j in range(len(type_cols)):\n",
    "        col = df1[type_cols[j]].values[0]\n",
    "        if col == 136:\n",
    "            df['Keeper touched'][i] = 1\n",
    "        else:\n",
    "            j +=1\n",
    "            df.at[i, str(qualifier_value)] = 1  # Mark as 1 if present\n",
    "            \n",
    "df['Keeper saved'] = 0\n",
    "for i in range(len(df)):\n",
    "    df1 = df.iloc[i:i+1,:]\n",
    "    j = 0\n",
    "    for j in range(len(type_cols)):\n",
    "        col = df1[type_cols[j]].values[0]\n",
    "        if col == 137:\n",
    "            df['Keeper saved'][i] = 1\n",
    "        else:\n",
    "            j +=1\n",
    "            df.at[i, str(qualifier_value)] = 1  # Mark as 1 if present\n",
    "            \n",
    "df['Block hand'] = 0\n",
    "for i in range(len(df)):\n",
    "    df1 = df.iloc[i:i+1,:]\n",
    "    j = 0\n",
    "    for j in range(len(type_cols)):\n",
    "        col = df1[type_cols[j]].values[0]\n",
    "        if col == 192:\n",
    "            df['Block hand'][i] = 1\n",
    "        else:\n",
    "            j +=1\n",
    "            df.at[i, str(qualifier_value)] = 1  # Mark as 1 if present\n",
    "            \n",
    "df['Saved shot off target'] = 0\n",
    "for i in range(len(df)):\n",
    "    df1 = df.iloc[i:i+1,:]\n",
    "    j = 0\n",
    "    for j in range(len(type_cols)):\n",
    "        col = df1[type_cols[j]].values[0]\n",
    "        if col == 196:\n",
    "            df['Saved shot off target'][i] = 1\n",
    "        else:\n",
    "            j +=1\n",
    "            df.at[i, str(qualifier_value)] = 1  # Mark as 1 if present      \n",
    "            \n",
    "df['High claim'] = 0\n",
    "for i in range(len(df)):\n",
    "    df1 = df.iloc[i:i+1,:]\n",
    "    j = 0\n",
    "    for j in range(len(type_cols)):\n",
    "        col = df1[type_cols[j]].values[0]\n",
    "        if col == 88:\n",
    "            df['High claim'][i] = 1\n",
    "        else:\n",
    "            j +=1\n",
    "            df.at[i, str(qualifier_value)] = 1  # Mark as 1 if present  \n",
    "\n",
    "df['1 on 1'] = 0\n",
    "for i in range(len(df)):\n",
    "    df1 = df.iloc[i:i+1,:]\n",
    "    j = 0\n",
    "    for j in range(len(type_cols)):\n",
    "        col = df1[type_cols[j]].values[0]\n",
    "        if col == 89:\n",
    "            df['1 on 1'][i] = 1\n",
    "        else:\n",
    "            j +=1\n",
    "            df.at[i, str(qualifier_value)] = 1  # Mark as 1 if present   \n",
    "        \n",
    "df['Deflected save'] = 0\n",
    "for i in range(len(df)):\n",
    "    df1 = df.iloc[i:i+1,:]\n",
    "    j = 0\n",
    "    for j in range(len(type_cols)):\n",
    "        col = df1[type_cols[j]].values[0]\n",
    "        if col == 90:\n",
    "            df['Deflected save'][i] = 1\n",
    "        else:\n",
    "            j +=1\n",
    "            df.at[i, str(qualifier_value)] = 1  # Mark as 1 if present   \n",
    "            \n",
    "df['Dive and deflect'] = 0\n",
    "for i in range(len(df)):\n",
    "    df1 = df.iloc[i:i+1,:]\n",
    "    j = 0\n",
    "    for j in range(len(type_cols)):\n",
    "        col = df1[type_cols[j]].values[0]\n",
    "        if col == 91:\n",
    "            df['Dive and deflect'][i] = 1\n",
    "        else:\n",
    "            j +=1\n",
    "            df.at[i, str(qualifier_value)] = 1  # Mark as 1 if present  \n",
    "            \n",
    "df['Catch'] = 0\n",
    "for i in range(len(df)):\n",
    "    df1 = df.iloc[i:i+1,:]\n",
    "    j = 0\n",
    "    for j in range(len(type_cols)):\n",
    "        col = df1[type_cols[j]].values[0]\n",
    "        if col == 92:\n",
    "            df['Catch'][i] = 1\n",
    "        else:\n",
    "            j +=1\n",
    "            df.at[i, str(qualifier_value)] = 1  # Mark as 1 if present \n",
    "            \n",
    "df['Dive and catch'] = 0\n",
    "for i in range(len(df)):\n",
    "    df1 = df.iloc[i:i+1,:]\n",
    "    j = 0\n",
    "    for j in range(len(type_cols)):\n",
    "        col = df1[type_cols[j]].values[0]\n",
    "        if col == 93:\n",
    "            df['Dive and catch'][i] = 1\n",
    "        else:\n",
    "            j +=1\n",
    "            df.at[i, str(qualifier_value)] = 1  # Mark as 1 if present \n",
    "            \n",
    "df['Keeper throw'] = 0\n",
    "for i in range(len(df)):\n",
    "    df1 = df.iloc[i:i+1,:]\n",
    "    j = 0\n",
    "    for j in range(len(type_cols)):\n",
    "        col = df1[type_cols[j]].values[0]\n",
    "        if col == 123:\n",
    "            df['Keeper throw'][i] = 1\n",
    "        else:\n",
    "            j +=1\n",
    "            df.at[i, str(qualifier_value)] = 1  # Mark as 1 if present \n",
    "            \n",
    "df['Goal kick'] = 0\n",
    "for i in range(len(df)):\n",
    "    df1 = df.iloc[i:i+1,:]\n",
    "    j = 0\n",
    "    for j in range(len(type_cols)):\n",
    "        col = df1[type_cols[j]].values[0]\n",
    "        if col == 124:\n",
    "            df['Goal kick'][i] = 1\n",
    "        else:\n",
    "            j +=1\n",
    "            df.at[i, str(qualifier_value)] = 1  # Mark as 1 if present \n",
    "            \n",
    "df['Punch'] = 0\n",
    "for i in range(len(df)):\n",
    "    df1 = df.iloc[i:i+1,:]\n",
    "    j = 0\n",
    "    for j in range(len(type_cols)):\n",
    "        col = df1[type_cols[j]].values[0]\n",
    "        if col == 128:\n",
    "            df['Punch'][i] = 1\n",
    "        else:\n",
    "            j +=1\n",
    "            df.at[i, str(qualifier_value)] = 1  # Mark as 1 if present \n",
    "            \n",
    "df['Parried safe'] = 0\n",
    "for i in range(len(df)):\n",
    "    df1 = df.iloc[i:i+1,:]\n",
    "    j = 0\n",
    "    for j in range(len(type_cols)):\n",
    "        col = df1[type_cols[j]].values[0]\n",
    "        if col == 173:\n",
    "            df['Parried safe'][i] = 1\n",
    "        else:\n",
    "            j +=1\n",
    "            df.at[i, str(qualifier_value)] = 1  # Mark as 1 if present \n",
    "            \n",
    "df['Parried danger'] = 0\n",
    "for i in range(len(df)):\n",
    "    df1 = df.iloc[i:i+1,:]\n",
    "    j = 0\n",
    "    for j in range(len(type_cols)):\n",
    "        col = df1[type_cols[j]].values[0]\n",
    "        if col == 173:\n",
    "            df['Parried danger'][i] = 1\n",
    "        else:\n",
    "            j +=1\n",
    "            df.at[i, str(qualifier_value)] = 1  # Mark as 1 if present \n",
    "            \n",
    "df['Fingertip'] = 0\n",
    "for i in range(len(df)):\n",
    "    df1 = df.iloc[i:i+1,:]\n",
    "    j = 0\n",
    "    for j in range(len(type_cols)):\n",
    "        col = df1[type_cols[j]].values[0]\n",
    "        if col == 175:\n",
    "            df['Fingertip'][i] = 1\n",
    "        else:\n",
    "            j +=1\n",
    "            df.at[i, str(qualifier_value)] = 1  # Mark as 1 if present \n",
    "            \n",
    "df['Caught'] = 0\n",
    "for i in range(len(df)):\n",
    "    df1 = df.iloc[i:i+1,:]\n",
    "    j = 0\n",
    "    for j in range(len(type_cols)):\n",
    "        col = df1[type_cols[j]].values[0]\n",
    "        if col == 176:\n",
    "            df['Caught'][i] = 1\n",
    "        else:\n",
    "            j +=1\n",
    "            df.at[i, str(qualifier_value)] = 1  # Mark as 1 if present \n",
    "            \n",
    "df['Collected'] = 0\n",
    "for i in range(len(df)):\n",
    "    df1 = df.iloc[i:i+1,:]\n",
    "    j = 0\n",
    "    for j in range(len(type_cols)):\n",
    "        col = df1[type_cols[j]].values[0]\n",
    "        if col == 177:\n",
    "            df['Collected'][i] = 1\n",
    "        else:\n",
    "            j +=1\n",
    "            df.at[i, str(qualifier_value)] = 1  # Mark as 1 if present \n",
    "            \n",
    "df['Diving'] = 0\n",
    "for i in range(len(df)):\n",
    "    df1 = df.iloc[i:i+1,:]\n",
    "    j = 0\n",
    "    for j in range(len(type_cols)):\n",
    "        col = df1[type_cols[j]].values[0]\n",
    "        if col == 177:\n",
    "            df['Diving'][i] = 1\n",
    "        else:\n",
    "            j +=1\n",
    "            df.at[i, str(qualifier_value)] = 1  # Mark as 1 if present \n",
    "            \n",
    "df['Standing save'] = 0\n",
    "for i in range(len(df)):\n",
    "    df1 = df.iloc[i:i+1,:]\n",
    "    j = 0\n",
    "    for j in range(len(type_cols)):\n",
    "        col = df1[type_cols[j]].values[0]\n",
    "        if col == 178:\n",
    "            df['Standing save'][i] = 1\n",
    "        else:\n",
    "            j +=1\n",
    "            df.at[i, str(qualifier_value)] = 1  # Mark as 1 if present \n",
    "            \n",
    "df['Stooping'] = 0\n",
    "for i in range(len(df)):\n",
    "    df1 = df.iloc[i:i+1,:]\n",
    "    j = 0\n",
    "    for j in range(len(type_cols)):\n",
    "        col = df1[type_cols[j]].values[0]\n",
    "        if col == 180:\n",
    "            df['Stooping'][i] = 1\n",
    "        else:\n",
    "            j +=1\n",
    "            df.at[i, str(qualifier_value)] = 1  # Mark as 1 if present \n",
    "            \n",
    "df['Reaching'] = 0\n",
    "for i in range(len(df)):\n",
    "    df1 = df.iloc[i:i+1,:]\n",
    "    j = 0\n",
    "    for j in range(len(type_cols)):\n",
    "        col = df1[type_cols[j]].values[0]\n",
    "        if col == 181:\n",
    "            df['Reaching'][i] = 1\n",
    "        else:\n",
    "            j +=1\n",
    "            df.at[i, str(qualifier_value)] = 1  # Mark as 1 if present \n",
    "            \n",
    "df['Hands'] = 0\n",
    "for i in range(len(df)):\n",
    "    df1 = df.iloc[i:i+1,:]\n",
    "    j = 0\n",
    "    for j in range(len(type_cols)):\n",
    "        col = df1[type_cols[j]].values[0]\n",
    "        if col == 182:\n",
    "            df['Hands'][i] = 1\n",
    "        else:\n",
    "            j +=1\n",
    "            df.at[i, str(qualifier_value)] = 1  # Mark as 1 if present \n",
    "                        \n",
    "df['Feet'] = 0\n",
    "for i in range(len(df)):\n",
    "    df1 = df.iloc[i:i+1,:]\n",
    "    j = 0\n",
    "    for j in range(len(type_cols)):\n",
    "        col = df1[type_cols[j]].values[0]\n",
    "        if col == 183:\n",
    "            df['Feet'][i] = 1\n",
    "        else:\n",
    "            j +=1\n",
    "            df.at[i, str(qualifier_value)] = 1  # Mark as 1 if present \n",
    "            \n",
    "df['Scored'] = 0\n",
    "for i in range(len(df)):\n",
    "    df1 = df.iloc[i:i+1,:]\n",
    "    j = 0\n",
    "    for j in range(len(type_cols)):\n",
    "        col = df1[type_cols[j]].values[0]\n",
    "        if col == 186:\n",
    "            df['Scored'][i] = 1\n",
    "        else:\n",
    "            j +=1\n",
    "            df.at[i, str(qualifier_value)] = 1  # Mark as 1 if present \n",
    "            \n",
    "df['Saved'] = 0\n",
    "for i in range(len(df)):\n",
    "    df1 = df.iloc[i:i+1,:]\n",
    "    j = 0\n",
    "    for j in range(len(type_cols)):\n",
    "        col = df1[type_cols[j]].values[0]\n",
    "        if col == 187:\n",
    "            df['Saved'][i] = 1\n",
    "        else:\n",
    "            j +=1\n",
    "            df.at[i, str(qualifier_value)] = 1  # Mark as 1 if present \n",
    "            \n",
    "df['Missed'] = 0\n",
    "for i in range(len(df)):\n",
    "    df1 = df.iloc[i:i+1,:]\n",
    "    j = 0\n",
    "    for j in range(len(type_cols)):\n",
    "        col = df1[type_cols[j]].values[0]\n",
    "        if col == 188:\n",
    "            df['Missed'][i] = 1\n",
    "        else:\n",
    "            j +=1\n",
    "            df.at[i, str(qualifier_value)] = 1  # Mark as 1 if present \n",
    "            \n",
    "df['GK hoof'] = 0\n",
    "for i in range(len(df)):\n",
    "    df1 = df.iloc[i:i+1,:]\n",
    "    j = 0\n",
    "    for j in range(len(type_cols)):\n",
    "        col = df1[type_cols[j]].values[0]\n",
    "        if col == 198:\n",
    "            df['GK hoof'][i] = 1\n",
    "        else:\n",
    "            j +=1\n",
    "            df.at[i, str(qualifier_value)] = 1  # Mark as 1 if present \n",
    "            \n",
    "df['GK kick from hands'] = 0\n",
    "for i in range(len(df)):\n",
    "    df1 = df.iloc[i:i+1,:]\n",
    "    j = 0\n",
    "    for j in range(len(type_cols)):\n",
    "        col = df1[type_cols[j]].values[0]\n",
    "        if col == 198:\n",
    "            df['GK kick from hands'][i] = 1\n",
    "        else:\n",
    "            j +=1\n",
    "            df.at[i, str(qualifier_value)] = 1  # Mark as 1 if present \n",
    "            \n",
    "df['GoalMouthY'] = 0.0\n",
    "df['GoalMouthZ'] = 0.0\n",
    "for i in range(len(df)):            \n",
    "    df1 = df.iloc[i:i+1,:]\n",
    "    j = 0\n",
    "    for j in range(len(type_cols)):\n",
    "        col = df1[type_cols[j]].values[0]\n",
    "        if col == 102:\n",
    "            mouthy = df1.loc[:,'qualifier/%i/value' %j].values[0]\n",
    "            df['GoalMouthY'][i] = mouthy\n",
    "        else:\n",
    "            j +=1\n",
    "    k = 0\n",
    "    for k in range(len(type_cols)):\n",
    "        col = df1[type_cols[k]].values[0]\n",
    "        if col == 103:\n",
    "            mouthz = df1.loc[:,'qualifier/%i/value' %k].values[0]\n",
    "            df['GoalMouthZ'][i] = mouthz\n",
    "        else:\n",
    "            k +=1\n",
    "            \n",
    "df['pass_angle'] = 0.0\n",
    "df['pass_length'] = 0.0\n",
    "for i in range(len(df)):\n",
    "    df1 = df.iloc[i:i+1,:]\n",
    "    j = 0\n",
    "    for j in range(len(type_cols)):\n",
    "        col = df1[type_cols[j]].values[0]\n",
    "        if col == 213:\n",
    "            angle = df1.loc[:,'qualifier/%i/value' %j].values[0]\n",
    "            df.pass_angle[i] = angle\n",
    "        else:\n",
    "            j +=1\n",
    "    k = 0\n",
    "    for k in range(len(type_cols)):\n",
    "        col = df1[type_cols[k]].values[0]\n",
    "        if col == 212:\n",
    "            length = df1.loc[:,'qualifier/%i/value' %k].values[0]\n",
    "            df.pass_length[i] = length\n",
    "        else:\n",
    "            k +=1\n",
    "            \n",
    "# Save the updated DataFrame to an Excel file\n",
    "output_file_path = \"data_gk.xlsx\"\n",
    "df.to_excel(output_file_path, index=False)\n",
    "\n",
    "print(f\"Processed data saved to: {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "295b8c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marclambertes/anaconda3/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ xSave predictions saved to xSave_Predictions.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marclambertes/anaconda3/lib/python3.10/site-packages/sklearn/base.py:420: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"data_gk.xlsx\"  # Update with actual path\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Remove duplicate columns if any\n",
    "df = df.loc[:, ~df.columns.duplicated()]\n",
    "\n",
    "# Keep only rows where 'typeId' is a shot type\n",
    "valid_shots = [\"Miss\", \"Post\", \"Shot on Target\", \"Goal\"]\n",
    "df = df[df['typeId'].isin(valid_shots)]\n",
    "\n",
    "# Stop execution if dataset is empty after filtering\n",
    "if df.empty:\n",
    "    raise ValueError(\"❌ ERROR: No valid shot data found! Check 'typeId' values.\")\n",
    "\n",
    "# ---------------------------\n",
    "# STEP 1: ONE-HOT ENCODE typeId (Shot Type)\n",
    "# ---------------------------\n",
    "encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "shot_encoded = encoder.fit_transform(df[['typeId']])\n",
    "\n",
    "# Convert encoded shots to DataFrame\n",
    "shot_encoded_df = pd.DataFrame(shot_encoded, columns=encoder.get_feature_names_out(['typeId']))\n",
    "\n",
    "# Merge with original dataset\n",
    "df = pd.concat([df, shot_encoded_df], axis=1)\n",
    "\n",
    "# Drop original 'typeId' column\n",
    "df.drop(columns=['typeId'], inplace=True)\n",
    "\n",
    "# Define relevant features\n",
    "features = list(encoder.get_feature_names_out(['typeId'])) + [\n",
    "    'GoalMouthY', 'GoalMouthZ', 'pass_angle', 'pass_length', \n",
    "    'Swerve left', 'Swerve right', 'Deflection', 'Keeper touched', \n",
    "    '1 on 1', 'Block hand', 'Saved shot off target', 'High claim', 'Deflected save'\n",
    "]\n",
    "\n",
    "# Ensure required features exist\n",
    "available_features = [col for col in features if col in df.columns]\n",
    "df_filtered = df[available_features].copy()\n",
    "\n",
    "# Handle missing values by filling them with median values\n",
    "df_filtered.fillna(df_filtered.median(), inplace=True)\n",
    "\n",
    "# Stop execution if dataset is empty after filtering\n",
    "if df_filtered.empty:\n",
    "    raise ValueError(\"❌ ERROR: Data is empty after feature selection! Check missing values.\")\n",
    "\n",
    "# ---------------------------\n",
    "# STEP 2: CLUSTER SHOTS TO ESTIMATE DIFFICULTY\n",
    "# ---------------------------\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df_filtered)\n",
    "\n",
    "# Apply PCA for dimensionality reduction\n",
    "pca = PCA(n_components=3)  # Reduce to 3 key features\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Use K-Means to cluster shots by difficulty\n",
    "kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)  # Clusters: Easy, Medium, Hard\n",
    "df_filtered['Shot_Difficulty'] = kmeans.fit_predict(X_pca)\n",
    "\n",
    "# Normalize difficulty scores (0 = easy, 1 = medium, 2 = hard → scale to 0-1)\n",
    "df_filtered['Shot_Difficulty'] = df_filtered['Shot_Difficulty'] / 2.0\n",
    "\n",
    "# ---------------------------\n",
    "# STEP 3: TRAIN REGRESSION MODEL TO PREDICT xSAVE\n",
    "# ---------------------------\n",
    "X_train = df_filtered.drop(columns=['Shot_Difficulty'])\n",
    "y_train = df_filtered['Shot_Difficulty']\n",
    "\n",
    "# Train a regression model to predict expected save probability\n",
    "regressor = RandomForestRegressor(n_estimators=200, max_depth=10, random_state=42)\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# ---------------------------\n",
    "# STEP 4: APPLY MODEL TO DUMMY SHOTS\n",
    "# ---------------------------\n",
    "dummy_shots = pd.DataFrame({\n",
    "    'typeId': np.random.choice([\"Miss\", \"Post\", \"Shot on Target\", \"Goal\"], 10),\n",
    "    'GoalMouthY': np.random.uniform(0, 8, 10),  # Goal area Y\n",
    "    'GoalMouthZ': np.random.uniform(0, 2, 10),  # Goal height\n",
    "    'pass_angle': np.random.uniform(-3.14, 3.14, 10),  # Angle in radians\n",
    "    'pass_length': np.random.uniform(5, 40, 10),  # Shot distance\n",
    "    'Swerve left': np.random.choice([0, 1], 10),\n",
    "    'Swerve right': np.random.choice([0, 1], 10),\n",
    "    'Deflection': np.random.choice([0, 1], 10),\n",
    "    'Keeper touched': np.random.choice([0, 1], 10),\n",
    "    '1 on 1': np.random.choice([0, 1], 10),\n",
    "    'Block hand': np.random.choice([0, 1], 10),\n",
    "    'Saved shot off target': np.random.choice([0, 1], 10),\n",
    "    'High claim': np.random.choice([0, 1], 10),\n",
    "    'Deflected save': np.random.choice([0, 1], 10)\n",
    "})\n",
    "\n",
    "# One-hot encode dummy shots\n",
    "dummy_shots_encoded = encoder.transform(dummy_shots[['typeId']])\n",
    "dummy_shots_df = pd.DataFrame(dummy_shots_encoded, columns=encoder.get_feature_names_out(['typeId']))\n",
    "\n",
    "# Merge with dummy shots DataFrame\n",
    "dummy_shots = pd.concat([dummy_shots, dummy_shots_df], axis=1)\n",
    "\n",
    "# Drop original typeId column\n",
    "dummy_shots.drop(columns=['typeId'], inplace=True)\n",
    "\n",
    "# Ensure dummy shot columns match training features (fixes feature mismatch error)\n",
    "for col in features:\n",
    "    if col not in dummy_shots:\n",
    "        dummy_shots[col] = 0  # Add missing columns with default value\n",
    "\n",
    "# Sort columns to match model training order\n",
    "dummy_shots = dummy_shots[features]\n",
    "\n",
    "# Standardize dummy shot data\n",
    "dummy_shots_scaled = scaler.transform(dummy_shots)\n",
    "\n",
    "# Predict xSave probability for each dummy shot\n",
    "dummy_shots['xSave_Probability'] = regressor.predict(dummy_shots_scaled)\n",
    "\n",
    "# ---------------------------\n",
    "# STEP 5: SAVE TO EXCEL\n",
    "# ---------------------------\n",
    "output_file_path = \"xSave_Predictions.xlsx\"\n",
    "dummy_shots.to_excel(output_file_path, index=False)\n",
    "\n",
    "print(f\"✅ xSave predictions saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0a62fa92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/68/mhmqcpdn52943pyql2n4wj440000gn/T/ipykernel_80422/172275192.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = 0 if \"endX\" not in col_name and \"GoalMouthY\" not in col_name else 0.0\n",
      "/var/folders/68/mhmqcpdn52943pyql2n4wj440000gn/T/ipykernel_80422/172275192.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = 0 if \"endX\" not in col_name and \"GoalMouthY\" not in col_name else 0.0\n",
      "/var/folders/68/mhmqcpdn52943pyql2n4wj440000gn/T/ipykernel_80422/172275192.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = 0 if \"endX\" not in col_name and \"GoalMouthY\" not in col_name else 0.0\n",
      "/var/folders/68/mhmqcpdn52943pyql2n4wj440000gn/T/ipykernel_80422/172275192.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = 0 if \"endX\" not in col_name and \"GoalMouthY\" not in col_name else 0.0\n",
      "/var/folders/68/mhmqcpdn52943pyql2n4wj440000gn/T/ipykernel_80422/172275192.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = 0 if \"endX\" not in col_name and \"GoalMouthY\" not in col_name else 0.0\n",
      "/var/folders/68/mhmqcpdn52943pyql2n4wj440000gn/T/ipykernel_80422/172275192.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = 0 if \"endX\" not in col_name and \"GoalMouthY\" not in col_name else 0.0\n",
      "/var/folders/68/mhmqcpdn52943pyql2n4wj440000gn/T/ipykernel_80422/172275192.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = 0 if \"endX\" not in col_name and \"GoalMouthY\" not in col_name else 0.0\n",
      "/var/folders/68/mhmqcpdn52943pyql2n4wj440000gn/T/ipykernel_80422/172275192.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = 0 if \"endX\" not in col_name and \"GoalMouthY\" not in col_name else 0.0\n",
      "/Users/marclambertes/anaconda3/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model trained! Mean Squared Error: 0.0000\n",
      "✅ Model, scaler, and encoder saved to disk.\n",
      "✅ Predicted xSave: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import joblib  # For saving the trained model\n",
    "\n",
    "# ---------------------------\n",
    "# STEP 1: LOAD MULTIPLE CSV FILES\n",
    "# ---------------------------\n",
    "folder_path = \"/Users/marclambertes/Python/Matches/Men/2024-2025/Eredivisie 2024-2025/\"  # Update this\n",
    "all_files = glob.glob(folder_path + \"*.csv\")  # Get all CSV files in the folder\n",
    "\n",
    "# Define shot type mapping\n",
    "shot_mapping = {13: \"Miss\", 14: \"Post\", 15: \"Shot on Target\", 16: \"Goal\"}\n",
    "\n",
    "# Load and combine all files\n",
    "df_list = []\n",
    "for file in all_files:\n",
    "    df_temp = pd.read_csv(file)\n",
    "    if 'typeId' in df_temp.columns:\n",
    "        df_temp = df_temp[df_temp['typeId'].isin(shot_mapping.keys())]  # Keep only valid shots\n",
    "        df_temp['typeId'] = df_temp['typeId'].map(shot_mapping)  # Map typeId to shot names\n",
    "        df_list.append(df_temp)\n",
    "    else:\n",
    "        print(f\"⚠ Skipping {file}: 'typeId' column not found\")\n",
    "\n",
    "# Concatenate all dataframes\n",
    "if df_list:\n",
    "    df = pd.concat(df_list, ignore_index=True)\n",
    "else:\n",
    "    raise ValueError(\"❌ ERROR: No valid shot data found! Check 'typeId' values in your CSV files.\")\n",
    "\n",
    "# ---------------------------\n",
    "# STEP 2: EXTRACT QUALIFIERS\n",
    "# ---------------------------\n",
    "\n",
    "# Identify qualifier columns\n",
    "type_cols = [col for col in df.columns if '/qualifierId' in col]\n",
    "\n",
    "# Initialize columns\n",
    "df[\"endX\"] = 0.0\n",
    "df[\"endY\"] = 0.0\n",
    "df[\"GoalMouthY\"] = 0.0\n",
    "df[\"GoalMouthZ\"] = 0.0\n",
    "df[\"pass_angle\"] = 0.0\n",
    "df[\"pass_length\"] = 0.0\n",
    "\n",
    "# List of relevant qualifiers to track\n",
    "qualifier_map = {\n",
    "    140: \"endX\",\n",
    "    141: \"endY\",\n",
    "    102: \"GoalMouthY\",\n",
    "    103: \"GoalMouthZ\",\n",
    "    213: \"pass_angle\",\n",
    "    212: \"pass_length\",\n",
    "    120: \"Swerve left\",\n",
    "    121: \"Swerve right\",\n",
    "    133: \"Deflection\",\n",
    "    136: \"Keeper touched\",\n",
    "    137: \"Keeper saved\",\n",
    "    192: \"Block hand\",\n",
    "    196: \"Saved shot off target\",\n",
    "    88: \"High claim\",\n",
    "    89: \"1 on 1\",\n",
    "    90: \"Deflected save\",\n",
    "    91: \"Dive and deflect\",\n",
    "    92: \"Catch\",\n",
    "    93: \"Dive and catch\",\n",
    "    123: \"Keeper throw\",\n",
    "    124: \"Goal kick\",\n",
    "    128: \"Punch\",\n",
    "    173: \"Parried safe\",\n",
    "    174: \"Parried danger\",\n",
    "    175: \"Fingertip\",\n",
    "    176: \"Caught\",\n",
    "    177: \"Collected\",\n",
    "    178: \"Diving\",\n",
    "    179: \"Standing save\",\n",
    "    180: \"Stooping\",\n",
    "    181: \"Reaching\",\n",
    "    182: \"Hands\",\n",
    "    183: \"Feet\",\n",
    "    186: \"Scored\",\n",
    "    187: \"Saved\",\n",
    "    188: \"Missed\",\n",
    "    190: \"GK hoof\",\n",
    "    198: \"GK kick from hands\",\n",
    "}\n",
    "\n",
    "# Initialize all qualifier-based columns with default values\n",
    "for col_name in qualifier_map.values():\n",
    "    df[col_name] = 0 if \"endX\" not in col_name and \"GoalMouthY\" not in col_name else 0.0\n",
    "\n",
    "# Extract values from qualifiers\n",
    "for i, row in df.iterrows():\n",
    "    for j, col in enumerate(type_cols):\n",
    "        qualifier_value = row[col]\n",
    "        if qualifier_value in qualifier_map:\n",
    "            column_name = qualifier_map[qualifier_value]\n",
    "            if column_name in [\"endX\", \"endY\", \"GoalMouthY\", \"GoalMouthZ\", \"pass_angle\", \"pass_length\"]:\n",
    "                df.at[i, column_name] = row.get(f\"qualifier/{j}/value\", 0.0)\n",
    "            else:\n",
    "                df.at[i, column_name] = 1  # Binary indicators\n",
    "\n",
    "# Replace NaN values with 0 for safety\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "# ---------------------------\n",
    "# STEP 3: ONE-HOT ENCODE typeId (Shot Type)\n",
    "# ---------------------------\n",
    "encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "shot_encoded = encoder.fit_transform(df[['typeId']])\n",
    "shot_encoded_df = pd.DataFrame(shot_encoded, columns=encoder.get_feature_names_out(['typeId']))\n",
    "df = pd.concat([df, shot_encoded_df], axis=1)\n",
    "df.drop(columns=['typeId'], inplace=True)\n",
    "\n",
    "# Define relevant features\n",
    "features = list(encoder.get_feature_names_out(['typeId'])) + list(qualifier_map.values())\n",
    "\n",
    "# Ensure required features exist\n",
    "available_features = [col for col in features if col in df.columns]\n",
    "df_filtered = df[available_features].copy()\n",
    "\n",
    "# ---------------------------\n",
    "# STEP 4: TRAIN THE MODEL\n",
    "# ---------------------------\n",
    "\n",
    "# Create target variable: 1 for saved shots, 0 for goals\n",
    "df_filtered['Target'] = np.where(df['typeId_Goal'] == 1, 0, 1)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X = df_filtered.drop(columns=['Target'])\n",
    "y = df_filtered['Target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train RandomForestRegressor\n",
    "regressor = RandomForestRegressor(n_estimators=200, max_depth=10, random_state=42)\n",
    "regressor.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = regressor.predict(X_test_scaled)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"✅ Model trained! Mean Squared Error: {mse:.4f}\")\n",
    "\n",
    "# Save the model and scaler for future use\n",
    "joblib.dump(regressor, \"xSave_model.pkl\")\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "joblib.dump(encoder, \"encoder.pkl\")\n",
    "print(\"✅ Model, scaler, and encoder saved to disk.\")\n",
    "\n",
    "# ---------------------------\n",
    "# STEP 5: PREDICT xSave FOR NEW SHOTS\n",
    "# ---------------------------\n",
    "\n",
    "def predict_xSave(new_shot):\n",
    "    \"\"\"\n",
    "    Predict xSave for a new shot.\n",
    "    :param new_shot: Dictionary containing shot features (e.g., endX, endY, GoalMouthY, etc.)\n",
    "    :return: xSave probability\n",
    "    \"\"\"\n",
    "    # Convert new shot to DataFrame\n",
    "    new_shot_df = pd.DataFrame([new_shot])\n",
    "\n",
    "    # One-hot encode the shot type\n",
    "    shot_encoded = encoder.transform(new_shot_df[['typeId']])\n",
    "    shot_encoded_df = pd.DataFrame(shot_encoded, columns=encoder.get_feature_names_out(['typeId']))\n",
    "    new_shot_df = pd.concat([new_shot_df, shot_encoded_df], axis=1)\n",
    "    new_shot_df.drop(columns=['typeId'], inplace=True)\n",
    "\n",
    "    # Ensure all required features are present\n",
    "    for col in features:\n",
    "        if col not in new_shot_df:\n",
    "            new_shot_df[col] = 0\n",
    "\n",
    "    # Scale the features\n",
    "    new_shot_scaled = scaler.transform(new_shot_df[features])\n",
    "\n",
    "    # Predict xSave\n",
    "    xSave_probability = regressor.predict(new_shot_scaled)[0]\n",
    "    return xSave_probability\n",
    "\n",
    "# Example usage\n",
    "new_shot = {\n",
    "    'typeId': 'Shot on Target',\n",
    "    'endX': 0.85,\n",
    "    'endY': 0.5,\n",
    "    'GoalMouthY': 1.2,\n",
    "    'GoalMouthZ': 0.8,\n",
    "    'pass_angle': 0.5,\n",
    "    'pass_length': 20,\n",
    "    'Keeper saved': 0,\n",
    "    'Deflection': 0,\n",
    "}\n",
    "\n",
    "xSave = predict_xSave(new_shot)\n",
    "print(f\"✅ Predicted xSave: {xSave:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2e53d5fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Columns must be same length as key",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 71\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# Ensure numeric columns are of type float\u001b[39;00m\n\u001b[1;32m     70\u001b[0m numeric_columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGoalMouthY\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGoalMouthZ\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(qualifier_map\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[0;32m---> 71\u001b[0m new_shots_df[numeric_columns] \u001b[38;5;241m=\u001b[39m new_shots_df[numeric_columns]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# One-hot encode the 'typeId' column\u001b[39;00m\n\u001b[1;32m     74\u001b[0m shot_encoded \u001b[38;5;241m=\u001b[39m encoder\u001b[38;5;241m.\u001b[39mtransform(new_shots_df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtypeId\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/frame.py:3644\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3642\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_frame(key, value)\n\u001b[1;32m   3643\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, (Series, np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;28mlist\u001b[39m, Index)):\n\u001b[0;32m-> 3644\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3645\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, DataFrame):\n\u001b[1;32m   3646\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_item_frame_value(key, value)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/frame.py:3688\u001b[0m, in \u001b[0;36mDataFrame._setitem_array\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3686\u001b[0m     check_key_length(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, key, value)\n\u001b[1;32m   3687\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k1, k2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(key, value\u001b[38;5;241m.\u001b[39mcolumns):\n\u001b[0;32m-> 3688\u001b[0m         \u001b[38;5;28mself\u001b[39m[k1] \u001b[38;5;241m=\u001b[39m value[k2]\n\u001b[1;32m   3690\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_list_like(value):\n\u001b[1;32m   3691\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m key:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/frame.py:3646\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3644\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array(key, value)\n\u001b[1;32m   3645\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, DataFrame):\n\u001b[0;32m-> 3646\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item_frame_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3647\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[1;32m   3648\u001b[0m     is_list_like(value)\n\u001b[1;32m   3649\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique\n\u001b[1;32m   3650\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_indexer_for([key])) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(value)\n\u001b[1;32m   3651\u001b[0m ):\n\u001b[1;32m   3652\u001b[0m     \u001b[38;5;66;03m# Column to set is duplicated\u001b[39;00m\n\u001b[1;32m   3653\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/frame.py:3776\u001b[0m, in \u001b[0;36mDataFrame._set_item_frame_value\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3774\u001b[0m len_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_scalar(cols) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(cols)\n\u001b[1;32m   3775\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m len_cols \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(value\u001b[38;5;241m.\u001b[39mcolumns):\n\u001b[0;32m-> 3776\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumns must be same length as key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3778\u001b[0m \u001b[38;5;66;03m# align right-hand-side columns if self.columns\u001b[39;00m\n\u001b[1;32m   3779\u001b[0m \u001b[38;5;66;03m# is multi-index and self[key] is a sub-frame\u001b[39;00m\n\u001b[1;32m   3780\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m   3781\u001b[0m     loc, (\u001b[38;5;28mslice\u001b[39m, Series, np\u001b[38;5;241m.\u001b[39mndarray, Index)\n\u001b[1;32m   3782\u001b[0m ):\n",
      "\u001b[0;31mValueError\u001b[0m: Columns must be same length as key"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib  # For loading the trained model, scaler, and encoder\n",
    "\n",
    "# ---------------------------\n",
    "# STEP 1: LOAD THE TRAINED MODEL, SCALER, AND ENCODER\n",
    "# ---------------------------\n",
    "regressor = joblib.load(\"xSave_model.pkl\")\n",
    "scaler = joblib.load(\"scaler.pkl\")\n",
    "encoder = joblib.load(\"encoder.pkl\")\n",
    "\n",
    "# ---------------------------\n",
    "# STEP 2: LOAD SHOTS FROM A CSV FILE\n",
    "# ---------------------------\n",
    "csv_path = \"/Users/marclambertes/Python/Matches/Men/2024-2025/Premier League 2024-2025/Nottm Forest 1-0 Man City.csv\"  # Update this path\n",
    "new_shots_df = pd.read_csv(csv_path)\n",
    "\n",
    "# Ensure the CSV has the required column\n",
    "if 'typeId' not in new_shots_df.columns:\n",
    "    raise ValueError(\"❌ Missing required column: 'typeId'\")\n",
    "\n",
    "# ---------------------------\n",
    "# STEP 4: PREPROCESS THE NEW SHOTS\n",
    "# ---------------------------\n",
    "\n",
    "# Fill missing qualifier columns with default values\n",
    "qualifier_map = {\n",
    "    102: \"GoalMouthY\",\n",
    "    103: \"GoalMouthZ\",\n",
    "    120: \"Swerve left\",\n",
    "    121: \"Swerve right\",\n",
    "    133: \"Deflection\",\n",
    "    136: \"Keeper touched\",\n",
    "    137: \"Keeper saved\",\n",
    "    192: \"Block hand\",\n",
    "    196: \"Saved shot off target\",\n",
    "    88: \"High claim\",\n",
    "    89: \"1 on 1\",\n",
    "    90: \"Deflected save\",\n",
    "    91: \"Dive and deflect\",\n",
    "    92: \"Catch\",\n",
    "    93: \"Dive and catch\",\n",
    "    123: \"Keeper throw\",\n",
    "    124: \"Goal kick\",\n",
    "    128: \"Punch\",\n",
    "    173: \"Parried safe\",\n",
    "    174: \"Parried danger\",\n",
    "    175: \"Fingertip\",\n",
    "    176: \"Caught\",\n",
    "    177: \"Collected\",\n",
    "    178: \"Diving\",\n",
    "    179: \"Standing save\",\n",
    "    180: \"Stooping\",\n",
    "    181: \"Reaching\",\n",
    "    182: \"Hands\",\n",
    "    183: \"Feet\",\n",
    "    186: \"Scored\",\n",
    "    187: \"Saved\",\n",
    "    188: \"Missed\",\n",
    "    190: \"GK hoof\",\n",
    "    198: \"GK kick from hands\",\n",
    "}\n",
    "\n",
    "# Initialize missing qualifier columns with default values\n",
    "for col_name in qualifier_map.values():\n",
    "    if col_name not in new_shots_df.columns:\n",
    "        new_shots_df[col_name] = 0 if \"GoalMouthY\" not in col_name else 0.0\n",
    "\n",
    "# Ensure numeric columns are of type float\n",
    "numeric_columns = ['GoalMouthY', 'GoalMouthZ'] + list(qualifier_map.values())\n",
    "new_shots_df[numeric_columns] = new_shots_df[numeric_columns].astype(float)\n",
    "\n",
    "# One-hot encode the 'typeId' column\n",
    "shot_encoded = encoder.transform(new_shots_df[['typeId']])\n",
    "shot_encoded_df = pd.DataFrame(shot_encoded, columns=encoder.get_feature_names_out(['typeId']))\n",
    "\n",
    "# Ensure the one-hot encoded DataFrame has the same number of rows as the original DataFrame\n",
    "if len(shot_encoded_df) != len(new_shots_df):\n",
    "    raise ValueError(\"❌ One-hot encoded DataFrame has mismatched row length.\")\n",
    "\n",
    "# Concatenate the one-hot encoded DataFrame with the original DataFrame\n",
    "new_shots_df = pd.concat([new_shots_df.reset_index(drop=True), shot_encoded_df.reset_index(drop=True)], axis=1)\n",
    "new_shots_df.drop(columns=['typeId'], inplace=True)\n",
    "\n",
    "# Ensure all required features are present\n",
    "features = list(encoder.get_feature_names_out(['typeId'])) + list(qualifier_map.values())\n",
    "for col in features:\n",
    "    if col not in new_shots_df:\n",
    "        new_shots_df[col] = 0\n",
    "\n",
    "# Scale the features\n",
    "new_shots_scaled = scaler.transform(new_shots_df[features])\n",
    "\n",
    "# ---------------------------\n",
    "# STEP 5: PREDICT xSave FOR EACH SHOT\n",
    "# ---------------------------\n",
    "new_shots_df['xSave_Probability'] = regressor.predict(new_shots_scaled)\n",
    "\n",
    "# ---------------------------\n",
    "# STEP 6: SAVE PREDICTIONS TO CSV (EXCLUDING GoalMouthY AND GoalMouthZ)\n",
    "# ---------------------------\n",
    "# Drop GoalMouthY and GoalMouthZ from the final output\n",
    "output_df = new_shots_df.drop(columns=['GoalMouthY', 'GoalMouthZ'])\n",
    "\n",
    "# Save to CSV\n",
    "output_csv_path = \"xSave_predictions.csv\"\n",
    "output_df.to_csv(output_csv_path, index=False)\n",
    "print(f\"✅ xSave predictions saved to {output_csv_path}\")\n",
    "\n",
    "# Print the first few predictions\n",
    "print(output_df[['xSave_Probability']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf44c30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
